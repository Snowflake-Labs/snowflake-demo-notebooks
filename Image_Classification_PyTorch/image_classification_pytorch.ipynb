{
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark-img-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 09:04:07) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "80dd599ee9a854293af3fe6cea99dcbf69fd37c3a4a4fc1db31d3eee29094f56"
   }
  },
  "lastEditStatus": {
   "notebookId": "uu7lw6nyqihhpfxlw5au",
   "authorId": "94022846931",
   "authorName": "DASH",
   "authorEmail": "dash.desai@snowflake.com",
   "sessionId": "96582a03-fc0d-44dc-b4ef-d065a14be0d0",
   "lastEditTime": 1744320777010
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c443ab7-70ce-42d6-9884-2708b2651614",
   "metadata": {
    "name": "Image_Classification_PyTorch",
    "collapsed": false,
    "resultHeight": 250
   },
   "source": "# Image Classification using PyTorch\n\n## Overview\n\nIn this Notebook, we will review how to build image recognition application in Snowflake using Snowpark for Python, PyTorch, and Streamlit.\n\n### What Is Snowpark?\n\nThe set of libraries and runtimes in Snowflake that securely deploy and process non-SQL code, including Python, Java and Scala.\n\nFamiliar Client Side Libraries: Snowpark brings deeply integrated, DataFrame-style programming and OSS compatible APIs to the languages data practitioners like to use. It also includes the Snowpark ML API for more efficient ML modeling (public preview) and ML operations (private preview).\n\nFlexible Runtime Constructs: Snowpark provides flexible runtime constructs that allow users to bring in and run custom logic. Developers can seamlessly build data pipelines, ML models, and data applications with User-Defined Functions and Stored Procedures.\n\n### What is PyTorch?\n\nIt is one of the most popular open source machine learning frameworks that also happens to be pre-installed and available for developers to use in Snowpark. This means that you can load pre-trained PyTorch models in Snowpark for Python without having to manually install the library and manage all its dependencies.\n\nFor this particular application, we will be using [PyTorch implementation of MobileNet V3](https://github.com/d-li14/mobilenetv3.pytorch). *Note: A huge thank you to the [authors](https://github.com/d-li14/mobilenetv3.pytorch?_fsi=THrZMtDg,%20THrZMtDg&_fsi=THrZMtDg,%20THrZMtDg#citation) for the research and making the pre-trained models available under [MIT License](https://github.com/d-li14/mobilenetv3.pytorch/blob/master/LICENSE).*"
  },
  {
   "cell_type": "markdown",
   "id": "d8a92fd3-e769-4950-b40d-321297d0c09b",
   "metadata": {
    "name": "_Prerequisites",
    "collapsed": false
   },
   "source": "### Prerequisites\n\n* Install `cachetools`, `pandas`, `streamlit` and `snowflake-snowpark-python` packages. [Learn how.](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-import-packages)\n* Download files:\n    * https://sfquickstarts.s3.us-west-1.amazonaws.com/misc/pytorch/imagenet1000_clsidx_to_labels.txt\n    * https://sfquickstarts.s3.us-west-1.amazonaws.com/misc/pytorch/mobilenetv3-large-1cd25616.pth\n    * https://sfquickstarts.s3.us-west-1.amazonaws.com/misc/pytorch/mobilenetv3.py\n* Create Snowflake Internal stage (See below)\n* Create Snowflake Network Rule object (See below)\n* Create Snowflake External Access Integration object (See below)\n"
  },
  {
   "cell_type": "code",
   "id": "f19496e9-d22c-402c-9c43-53e799f56356",
   "metadata": {
    "language": "sql",
    "name": "Create_Stage"
   },
   "outputs": [],
   "source": "-- Create internal stage to host the PyTorch model files downloaded in the previous step and the User-Defined Function\nCREATE STAGE DASH_FILES DIRECTORY = ( ENABLE = true );",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5766532-5fe3-4ded-9b47-12c1040306db",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "-- Create Network Rule object for AWS S3 bucket where the images are store for this demo\nCREATE OR REPLACE NETWORK RULE sfquickstarts_s3_network_rule\n  MODE = EGRESS\n  TYPE = HOST_PORT\n  VALUE_LIST = ('sfquickstarts.s3.us-west-1.amazonaws.com');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03c4b1cc-f317-4e4d-bbc5-504ecceb86d0",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "-- Create External Access Integration object for the Network Rule created above so the User-Defined Function can access images stored on AWS S3 for this demo\nCREATE OR REPLACE EXTERNAL ACCESS INTEGRATION sfquickstarts_s3_access_integration\n  ALLOWED_NETWORK_RULES = (sfquickstarts_s3_network_rule)\n  ENABLED = true;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2e43623-c152-43aa-a220-b30c605eeefc",
   "metadata": {
    "name": "_Upload_Files",
    "collapsed": false
   },
   "source": "### *TODO: Before proceeding, use Snowsight to upload the downloaded files on stage `DASH_FILES`. [Learn how](https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage-ui#uploading-files-onto-a-stage).*"
  },
  {
   "cell_type": "markdown",
   "id": "059a3840-f57a-4061-a623-4c0f0cbc0c0a",
   "metadata": {
    "name": "_Import_Libraries",
    "collapsed": false
   },
   "source": "## Import libraries"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d57b21-7720-40a0-9a95-8431e0dd1e22",
   "metadata": {
    "name": "Import_Libraries",
    "language": "python",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Snowpark\nfrom snowflake.snowpark.functions import udf\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import col\nimport streamlit as st\n\n# Misc\nimport pandas as pd\nimport cachetools\n\nsession = get_active_session()"
  },
  {
   "cell_type": "markdown",
   "id": "41c7becc-255c-4da5-b35d-adc668755b16",
   "metadata": {
    "name": "_Image_Classify_UDF",
    "collapsed": false
   },
   "source": "## Creat and register User-Defined Function\n\nTo deploy the pre-trained model for inference, we will **create and register a Snowpark Python UDFs and add the model files as dependencies**. Once registered, getting new predictions is as simple as calling the function by passing in data. For more information on Snowpark Python User-Defined Functions, refer to the [docs](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc438df-3c19-4dc6-82ca-ba048c1b7fbf",
   "metadata": {
    "name": "Image_Classify_UDF",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "session.clear_packages()\nsession.clear_imports()\n\n# Add model files and test images as dependencies on the UDF\nsession.add_import('@dash_files/imagenet1000_clsidx_to_labels.txt')\nsession.add_import('@dash_files/mobilenetv3.py')\nsession.add_import('@dash_files/mobilenetv3-large-1cd25616.pth')\n\n# Add Python packages from Snowflake Anaconda channel\nsession.add_packages('snowflake-snowpark-python','torchvision','joblib','cachetools','requests')\n\n@cachetools.cached(cache={})\ndef load_class_mapping(filename):\n  with open(filename, \"r\") as f:\n   return f.read()\n\n@cachetools.cached(cache={})\ndef load_model():\n  import sys\n  import torch\n  from torchvision import models, transforms\n  import ast\n  from mobilenetv3 import mobilenetv3_large\n\n  IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n  import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n\n  model_file = import_dir + 'mobilenetv3-large-1cd25616.pth'\n  imgnet_class_mapping_file = import_dir + 'imagenet1000_clsidx_to_labels.txt'\n\n  IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n\n  transform = transforms.Compose([\n      transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n      transforms.CenterCrop(224),\n      transforms.ToTensor(),\n      transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n  ])\n\n  # Load the Imagenet {class: label} mapping\n  cls_idx = load_class_mapping(imgnet_class_mapping_file)\n  cls_idx = ast.literal_eval(cls_idx)\n\n  # Load pretrained image recognition model\n  model = mobilenetv3_large()\n  model.load_state_dict(torch.load(model_file))\n\n  # Configure pretrained model for inference\n  model.eval().requires_grad_(False)\n\n  return model, transform, cls_idx\n\n@udf(name='image_recognition_using_bytes',session=session,replace=True,is_permanent=True,stage_location='@dash_files')\ndef image_recognition_using_bytes(image_bytes_in_str: str) -> str:\n  from io import BytesIO\n  import torch\n  from PIL import Image\n\n  image_bytes = bytes.fromhex(image_bytes_in_str)\n\n  model, transform, cls_idx = load_model()\n  img = Image.open(BytesIO(image_bytes)).convert('RGB')\n  img = transform(img).unsqueeze(0)\n\n  # Get model output and human text prediction\n  logits = model(img)\n\n  outp = torch.nn.functional.softmax(logits, dim=1)\n  _, idx = torch.topk(outp, 1)\n  idx.squeeze_()\n  predicted_label = cls_idx[idx.item()]\n\n  return f\"{predicted_label}\"\n\n@udf(name='image_recognition',\n     session=session,\n     is_permanent=True,\n     stage_location='@dash_files',\n     if_not_exists=True,\n     external_access_integrations=['sfquickstarts_s3_access_integration'])\ndef image_recognition(image_url: str) -> str:\n    import requests\n    import torch\n    from PIL import Image\n    from io import BytesIO\n\n    predicted_label = 'N/A'\n    response = requests.get(image_url)\n    \n    if response.status_code == 200:\n        image = Image.open(BytesIO(response.content))\n\n        model, transform, cls_idx = load_model()\n\n        img_byte_arr = BytesIO()\n        image.save(img_byte_arr, format='JPEG')\n        img_byte_arr = img_byte_arr.getvalue()\n        \n        img = Image.open(BytesIO(img_byte_arr)).convert('RGB')\n        img = transform(img).unsqueeze(0)\n        \n        # # Get model output and human text prediction\n        logits = model(img)\n        \n        outp = torch.nn.functional.softmax(logits, dim=1)\n        _, idx = torch.topk(outp, 1)\n        idx.squeeze_()\n        predicted_label = cls_idx[idx.item()]\n        \n        return f\"{predicted_label}\"\n    else:\n        return(\"Failed to fetch the image. HTTP Status:\", response.status_code)"
  },
  {
   "cell_type": "markdown",
   "id": "755b2e20-a637-4622-ab69-2c00bf7a9741",
   "metadata": {
    "name": "_Image_Classify_Streamlit",
    "collapsed": false
   },
   "source": "## Streamlit Application\n\nLet's use 5 images of dogs and cats stored on AWS S3 to see how the pre-trained PyTorch model loaded as part of the User-Defined Function classifies them."
  },
  {
   "cell_type": "code",
   "id": "181d33df-0197-4bf2-a479-b962cab59c87",
   "metadata": {
    "language": "python",
    "name": "Image_Classify_Streamlit",
    "collapsed": false,
    "resultHeight": 412,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "base_s3_url = 'https://sfquickstarts.s3.us-west-1.amazonaws.com/misc/images'\nimages = ['dogs/001.jpg','dogs/002.jpg','cats/001.jpg','cats/003.jpg','dogs/003.jpg']\nwith st.status(\"Breed classification in progress...\") as status:\n    col1, col2, col3, col4 = st.columns(4, gap='small')\n    p_container = st.container()\n    col_index = 0\n    i = 1\n    for i in range(1,len(images)):\n        with p_container:\n            col = col1 if col_index == 0 else col2 \\\n                if col_index == 1 else col3 if col_index == 2 else col4\n            img = f\"{base_s3_url}/{images[i]}\"\n            with col:\n                sql = f\"\"\"select image_recognition('{img}') as classified_breed\"\"\"\n                classified_breed = session.sql(sql).to_pandas()['CLASSIFIED_BREED'].iloc[0]\n                st.image(img,caption=f\"{classified_breed}\",use_column_width=True)\n        if (i % 4) == 0:\n            col1, col2, col3, col4 = st.columns(4, gap='small')\n            p_container = st.container()\n            col_index = 0\n        else:\n            col_index += 1\n        i += 1                \n    status.update(label=\"Done!\", state=\"complete\", expanded=True)",
   "execution_count": null
  }
 ]
}