{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ydmfvq724z6dfhkiqvoj",
   "authorId": "6841714608330",
   "authorName": "CHANINN",
   "authorEmail": "chanin.nantasenamat@snowflake.com",
   "sessionId": "06da9889-bce2-4a11-b191-0cce05b8090a",
   "lastEditTime": 1751356107787
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dca037f-325f-4c07-8172-ac5686264dfe",
   "metadata": {
    "name": "md_title",
    "collapsed": false
   },
   "source": "# Process DataFrame with Modin and Snowflake Cortex\n\nIn this notebook, we'll use Snowflake Cortex to process the Avalanche product catalog data directly from a Modin DataFrame.\n\nHere's what we're covering in this end-to-end tutorial:\n1. Load the Avalanche product catalog data from an S3 bucket into a Snowflake stage\n2. Read CSV data into a Modin DataFrame\n3. Perform data processing using Cortex LLM functionalities: classify, translate, sentiment, summarize and extract answers\n4. Perform data post-processing to tidy up the DataFrame\n5. Write data to a Snowflake database table\n6. Query the newly created table\n7. Create a simple interactive UI with Streamlit"
  },
  {
   "cell_type": "markdown",
   "id": "b71310ea-25d5-4ffc-b9ed-6bf590300f1d",
   "metadata": {
    "name": "md_packages",
    "collapsed": false
   },
   "source": "## Install Prerequisite Libraries\n\nSnowflake Notebooks includes common Python libraries by default. To add more, use the **Packages** dropdown in the top right. \n\nLet's add these packages:\n- `modin` - Enables the use of Modin\n- `snowflake-ml-python` - Enables the use of Cortex LLM functions\n- `snowflake-snowpark-python` - Enables the use of Snowpark"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "py_packages"
   },
   "source": "# Import Python packages\nimport modin.pandas as pd\nimport snowflake.snowpark.modin.plugin\n\n# Connecting to Snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9b24f3f5-e61a-4f07-9b85-8330e1b0a528",
   "metadata": {
    "name": "md_stage",
    "collapsed": false
   },
   "source": "## Load data into Snowflake\n\nWe can load data from an S3 bucket and bring it into Snowflake.\n\nTo do this, we'll create a stage on Snowflake to house the data:"
  },
  {
   "cell_type": "code",
   "id": "48de1f20-5456-4a76-bc5d-bb00202eb3ea",
   "metadata": {
    "language": "sql",
    "name": "py_stage"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE AVALANCHE\n    URL = 's3://sfquickstarts/misc/avalanche/csv/';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f51dfae-d906-4d8d-a757-b8b1af92b706",
   "metadata": {
    "name": "md_list_stage",
    "collapsed": false
   },
   "source": "### List contents of a stage\n\nNext, we'll use `ls` to list the contents of our stage that is referred to as `@avalanche`, which is located within the same database and schema where this Notebook resides on when the Notebook was first created."
  },
  {
   "cell_type": "code",
   "id": "9d07adf1-ace3-4662-a129-f0a9fa41cd54",
   "metadata": {
    "language": "sql",
    "name": "py_list_stage"
   },
   "outputs": [],
   "source": "ls @avalanche/",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4dd2e4b5-162b-4af9-8444-69a1cc34016f",
   "metadata": {
    "name": "md_read_data",
    "collapsed": false
   },
   "source": "### Read CSV Data\n\nHere, we'll read in `@avalanche/product-catalog.csv` via Pandas' `pd.read_csv()` method.\n\nWe should see the following 3 columns:\n- `name`\n- `description`\n- `price`"
  },
  {
   "cell_type": "code",
   "id": "c86d7b25-7a36-48b3-8248-34032df440bb",
   "metadata": {
    "language": "python",
    "name": "py_read_data",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = pd.read_csv(\"@avalanche/product-catalog.csv\")\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74cf96e3-5822-49cb-9222-b0b66e7e6bb2",
   "metadata": {
    "name": "md_cortex",
    "collapsed": false
   },
   "source": "## Use Cortex for Data Pre-processing\n\nSnowflake Cortex offers powerful AI and ML capabilities directly within your Snowflake Data Cloud, including various functions for data/image pre-processing and analysis."
  },
  {
   "cell_type": "markdown",
   "id": "f77c4825-f475-48de-91e5-b99fe4545d46",
   "metadata": {
    "name": "md_classify",
    "collapsed": false
   },
   "source": "## Classify\n\nWe'll classify each entry of a specified column in a Modin DataFrame via the `apply()` method together with the `ClassifyText` function. In addition, we're comparing the use of the product `name` vs `description` to generate the categorical labels.\n\nYou'll also notice that we also provided a few possible categorical labels for Cortex to work with as a list (`[\"Apparel\",\"Accessories\"]`)."
  },
  {
   "cell_type": "code",
   "id": "eaf66684-a5b3-4b89-9e1a-c8b0749cbf32",
   "metadata": {
    "language": "python",
    "name": "py_classify"
   },
   "outputs": [],
   "source": "from snowflake.cortex import ClassifyText\n\ndf[\"label\"] = df[\"name\"].apply(ClassifyText, categories=[\"Apparel\",\"Accessories\"])\ndf[\"label2\"] = df[\"description\"].apply(ClassifyText, categories=[\"Apparel\",\"Accessories\"])\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "418080fe-0022-420b-b70f-5b845be4e699",
   "metadata": {
    "name": "md_classify_2",
    "collapsed": false
   },
   "source": "You'll noticed that the generated label for each entry is in a dictionary format with key-value pair: `{\"label\":\"Accessories\"}`. We'll extract only the value by applying the `get()` method.\n\nFinally, we'll drop the `label` and `label2` columns."
  },
  {
   "cell_type": "code",
   "id": "6812557f-5a33-4a22-bd4e-a3404bc79386",
   "metadata": {
    "language": "python",
    "name": "py_classify_2"
   },
   "outputs": [],
   "source": "df[\"category\"] = df[\"label\"].apply(lambda x: x.get('label'))\ndf[\"category2\"] = df[\"label2\"].apply(lambda x: x.get('label'))\n\ndf.drop([\"label\", \"label2\"], axis=1, inplace=True)\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2e32c9f8-6c28-41a2-bba1-20ff4b8dbaaf",
   "metadata": {
    "name": "md_translate",
    "collapsed": false
   },
   "source": "## Translate\n\nSimilar to the previous example, we can also use `apply()` together with `Translate` and `from_language` and `to_language` parameters to tell Cortex what languages to work with."
  },
  {
   "cell_type": "code",
   "id": "d34a0c8e-f82b-4495-b33d-0b02bf7eb209",
   "metadata": {
    "language": "python",
    "name": "py_translate"
   },
   "outputs": [],
   "source": "from snowflake.cortex import Translate\n\ndf[\"name_de\"] = df[\"name\"].apply(Translate, from_language=\"en\", to_language=\"de\")\ndf[\"description_de\"] = df[\"description\"].apply(Translate, from_language=\"en\", to_language=\"de\")\ndf[\"category_de\"] = df[\"category\"].apply(Translate, from_language=\"en\", to_language=\"de\")\ndf[\"category2_de\"] = df[\"category2\"].apply(Translate, from_language=\"en\", to_language=\"de\")\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e086e91a-df72-43a0-9802-2f1ba8428cf7",
   "metadata": {
    "name": "md_sentiment",
    "collapsed": false
   },
   "source": "## Sentiment\n\nLet's also compute the sentiment of the description (as a use case example) using `apply()` with the `Sentiment` function."
  },
  {
   "cell_type": "code",
   "id": "281e26ed-9005-41ea-bfd2-30a9aef92dc4",
   "metadata": {
    "language": "python",
    "name": "py_sentiment"
   },
   "outputs": [],
   "source": "from snowflake.cortex import Sentiment\n\ndf[\"sentiment_score\"] = df[\"description\"].apply(Sentiment)\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7ff6b5b-55f7-48a8-9d4c-ad82bcf16216",
   "metadata": {
    "name": "md_summarize",
    "collapsed": false
   },
   "source": "## Summarize\n\nWe'll also summarize the description text using `apply()` with the `Summarize` function. "
  },
  {
   "cell_type": "code",
   "id": "af7ef036-3e21-41e8-a759-e822742f7c8c",
   "metadata": {
    "language": "python",
    "name": "py_summarize"
   },
   "outputs": [],
   "source": "from snowflake.cortex import Summarize\n\ndf[\"description_summary\"] = df[\"description\"].apply(Summarize)\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69d76e6e-d1d8-4d2f-9627-10e626c2de88",
   "metadata": {
    "name": "md_extractanswer",
    "collapsed": false
   },
   "source": "## Extract Answer\n\nWe'll also summarize the description text using `apply()` with the `ExtractAnswer` function. "
  },
  {
   "cell_type": "code",
   "id": "29855b6c-008c-48a1-a9cf-bb70c3667819",
   "metadata": {
    "language": "python",
    "name": "py_extractanswer"
   },
   "outputs": [],
   "source": "from snowflake.cortex import ExtractAnswer\n\ndf[\"product\"] = df[\"name\"].apply(ExtractAnswer, question=\"What product is being mentioned?\")\ndf[\"product\"] = [x[0][\"answer\"] for x in df['product']]\n\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e3d3c6e-6862-4ce1-9b03-70943a0bcda8",
   "metadata": {
    "name": "md_postprocessing",
    "collapsed": false
   },
   "source": "## Data Post-processing\n\nHere, we'll remove the `$` symbol from the `price` column."
  },
  {
   "cell_type": "code",
   "id": "d27a5f4a-8fca-40a5-8c74-332b88398300",
   "metadata": {
    "language": "python",
    "name": "py_postprocessing"
   },
   "outputs": [],
   "source": "# For the price column, remove $ symbol and convert to numeric\ndf[\"price\"] = df[\"price\"].str.replace(\"$\", \"\", regex=False)\ndf[\"price\"] = pd.to_numeric(df[\"price\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a2d5e40-04ed-4a5b-af80-dc407d2be6b8",
   "metadata": {
    "language": "python",
    "name": "py_postprocessing_2"
   },
   "outputs": [],
   "source": "df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "77bade28-1621-45af-b7d1-6404228b305f",
   "metadata": {
    "name": "md_postprocessing_2",
    "collapsed": false
   },
   "source": "As the columns are of the `object` data type, we'll convert them to the `str` data type."
  },
  {
   "cell_type": "code",
   "id": "ec6413d1-9c05-469e-8e8a-377a3a885212",
   "metadata": {
    "language": "python",
    "name": "py_postprocessing_3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Convert all other columns to the string type\nfor col_name in df.columns:\n    if col_name != \"price\" and col_name != \"sentiment_score\":\n        df[col_name] = df[col_name].astype(str)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "48a9ccc4-3ed7-4d80-8b43-a6c03c67f484",
   "metadata": {
    "language": "python",
    "name": "py_df",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "058b3482-6b59-42c2-adf8-c9c59c4c5d8a",
   "metadata": {
    "name": "md_write_to_snowflake",
    "collapsed": false
   },
   "source": "## Write Data to Snowflake\n\nWriting data to Snowflake can be done from a Modin DataFrame using the `to_snowflake()` method:"
  },
  {
   "cell_type": "code",
   "id": "fd4ee07e-aae4-4679-929a-1572acf122c7",
   "metadata": {
    "language": "python",
    "name": "py_write_to_snowflake",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df.to_snowflake(\"avalanche_products\", if_exists=\"replace\", index=False )",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3394552-3f68-4e54-a081-fdfaccdf9e1b",
   "metadata": {
    "name": "md_query_data",
    "collapsed": false
   },
   "source": "## Read Data from a Snowflake Table"
  },
  {
   "cell_type": "markdown",
   "id": "4cfc613f-698d-4dcf-9049-8c778c6305a8",
   "metadata": {
    "name": "md_read_sql",
    "collapsed": false
   },
   "source": "### Read Data using SQL\nWe'll now query the data using SQL:"
  },
  {
   "cell_type": "code",
   "id": "e08ba96c-547f-4553-a585-82780331ee0f",
   "metadata": {
    "language": "sql",
    "name": "sql_read_data"
   },
   "outputs": [],
   "source": "SELECT * FROM CHANINN_DEMO_DATA.PUBLIC.AVALANCHE_PRODUCTS",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3bb0e8d-b7d7-4bb3-81f5-c16972881225",
   "metadata": {
    "name": "md_read_python",
    "collapsed": false
   },
   "source": "### Read Data using Python\n\nWe'll also read data using Python:"
  },
  {
   "cell_type": "code",
   "id": "c3962ce5-9c4f-404c-a644-0474b82d4c1d",
   "metadata": {
    "language": "python",
    "name": "py_read_snowflake",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "pd.read_snowflake(\"avalanche_products\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11e63eee-73b8-45ed-91e0-c9be9d400519",
   "metadata": {
    "name": "md_streamlit",
    "collapsed": false
   },
   "source": "## Streamlit Example"
  },
  {
   "cell_type": "code",
   "id": "947b7ca9-eed7-401f-80b9-1e44000714b0",
   "metadata": {
    "language": "python",
    "name": "py_streamlit",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\ndf = pd.read_snowflake(\"avalanche_products\")\n\n#df = sql_read_data.to_pandas()\n\n#df['sentiment_score'] = pd.to_numeric(df['sentiment_score'])\n\nst.header(\"Product Category Distribution\")\n\n# Selectbox for choosing the category column\nselected_category_column = st.selectbox(\n    \"Select Category Type:\",\n    (\"category\", \"category2\")\n)\n\n# Count the occurrences of each category based on the selected column\ncategory_counts = df[selected_category_column].value_counts().reset_index()\ncategory_counts.columns = ['Category', 'Count']\n\nst.bar_chart(category_counts, x='Category', y='Count', color='Category')\n\n\nst.header(\"Product Sentiment Analysis\")\n\n# Calculate metrics\nst.write(\"Overall Sentiment Scores:\")\n\ncols = st.columns(4)\n\nwith cols[0]:\n    st.metric(\"Mean Sentiment\", df['sentiment_score'].mean() )\nwith cols[1]:\n    st.metric(\"Min Sentiment\", df['sentiment_score'].min() )\nwith cols[2]:\n    st.metric(\"Max Sentiment\", df['sentiment_score'].max() )\nwith cols[3]:\n    st.metric(\"Standard Deviation\", df['sentiment_score'].std() )\n\n# Create a bar chart showing sentiment scores for all products\nst.write(\"Individual Product Sentiment Scores:\")\noption = st.selectbox(\"Color bar by\", (\"name\", \"sentiment_score\"))\nst.bar_chart(df[['name', 'sentiment_score']], x='name', y='sentiment_score', color=option)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9479d7f-ca49-4a04-a4d8-7008454cd62f",
   "metadata": {
    "name": "md_resources",
    "collapsed": false
   },
   "source": "## Resources\n- [pandas on Snowflake](https://docs.snowflake.com/en/developer-guide/snowpark/python/pandas-on-snowflake)\n- [Using Snowflake Cortex LLM functions with Snowpark pandas](https://docs.snowflake.com/en/developer-guide/snowpark/python/pandas-on-snowflake#using-snowflake-cortex-llm-functions-with-snowpark-pandas)\n- [Snowflake Cortex AI](https://www.snowflake.com/en/product/features/cortex/)"
  }
 ]
}