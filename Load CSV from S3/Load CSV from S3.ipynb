{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13f35857-7833-4c7a-820b-421f7156fc94",
      "metadata": {
        "collapsed": false,
        "name": "cell1"
      },
      "source": [
        "# How to load CSV files from stage to Snowflake Notebooks üìÅ\n",
        "\n",
        "In this example, we will show how you can load a CSV file from stage and create a table with Snowpark. \n",
        "\n",
        "First, let's use the `get_active_session` command to get the [session](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.Session#snowflake.snowpark.Session) context variable to work with Snowpark as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4babf2c9-2d53-48dc-9b2e-07cda9bcc03c",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "cell2"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "# Add a query tag to the session. This helps with troubleshooting and performance monitoring.\n",
        "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
        "                     \"name\":\"notebook_demo_pack\", \n",
        "                     \"version\":{\"major\":1, \"minor\":0},\n",
        "                     \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\", \"vignette\":\"csv_from_s3\"}}\n",
        "print(session)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8151396-3ae3-4991-8ef0-be82fc33f363",
      "metadata": {
        "collapsed": false,
        "name": "cell3"
      },
      "source": [
        "Next, we will create an [external stage](https://docs.snowflake.com/en/sql-reference/sql/create-stage) that references data files stored in a location outside of Snowflake, in this case, the data lives in a [S3 bucket](https://docs.snowflake.com/en/user-guide/data-load-s3-create-stage)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d7f866-a698-457f-8bd0-4deff26ba329",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "sql",
        "name": "cell4"
      },
      "outputs": [],
      "source": [
        "CREATE STAGE IF NOT EXISTS TASTYBYTE_STAGE \n",
        "\tURL = 's3://sfquickstarts/frostbyte_tastybytes/';"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "614a9f59-b202-4102-81e8-192b66b656fd",
      "metadata": {
        "collapsed": false,
        "name": "cell5"
      },
      "source": [
        "Let's take a look at the files in the stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fdb36a-f3f6-46b0-92db-e06a28b14867",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "sql",
        "name": "cell6"
      },
      "outputs": [],
      "source": [
        "LS @TASTYBYTE_STAGE/app/app_orders;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9feb2dbb-8752-41c1-bd88-f2075e89f4ea",
      "metadata": {
        "collapsed": false,
        "name": "cell7"
      },
      "source": [
        "We can use [Snowpark DataFrameReader](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.14.0/api/snowflake.snowpark.DataFrameReader) to read in the CSV file.\n",
        "\n",
        "By using the `infer_schema = True` option, Snowflake will automatically infer the schema based on data types present in CSV file, so that you don't need to specify the schema beforehand. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf5c75a-b4e8-4212-a645-b8d63102757d",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell8"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame that is configured to load data from the CSV file.\n",
        "df = session.read.options({\"infer_schema\":True}).csv('@TASTYBYTE_STAGE/app/app_orders/app_order_detail.csv.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81196d0e-3979-46f1-b11d-871082171f61",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell9"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b0bc16-c31c-4cf0-8bf0-f2fdcdbfac0f",
      "metadata": {
        "collapsed": false,
        "name": "cell10"
      },
      "source": [
        "Now that the data is loaded into a Snowpark DataFrame, we can work with the data using [Snowpark DataFrame API](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame). \n",
        "\n",
        "For example, I can compute descriptive statistics on the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac152b7-8c98-4e0a-9ecc-42f2c104f49d",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell11"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ff2c51-66d9-4ca4-a060-0b40286ae37c",
      "metadata": {
        "collapsed": false,
        "name": "cell12"
      },
      "source": [
        "We can write the dataframe into a table called `APP_ORDER` and query it with SQL. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7b5940-47cb-438c-a666-817267b4bf39",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "cell13"
      },
      "outputs": [],
      "source": [
        "df.write.mode(\"overwrite\").save_as_table(\"APP_ORDER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e335b9-f60a-4971-aec8-288f0470340b",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "sql",
        "name": "cell14"
      },
      "outputs": [],
      "source": [
        "-- Preview the newly created APP_ORDER table\n",
        "SELECT * from APP_ORDER;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966f07d5-d246-49da-b133-6ab39fb0578d",
      "metadata": {
        "collapsed": false,
        "name": "cell15"
      },
      "source": [
        "Finally, we show how you can read the table back to Snowpark via the `session.table` syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76dd9c74-019d-47ff-a462-10499503bace",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "cell16"
      },
      "outputs": [],
      "source": [
        "df = session.table(\"APP_ORDER\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca22f85f-9073-44e6-a255-e34155b19bbb",
      "metadata": {
        "collapsed": false,
        "name": "cell17"
      },
      "source": [
        "From here, you can continue to query and process the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff779a9-c9ba-434d-b098-2564b9b6e337",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell18"
      },
      "outputs": [],
      "source": [
        "df.groupBy('\"c4\"').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792359f0-42fa-4639-b286-f8a8afeb1188",
      "metadata": {
        "codeCollapsed": false,
        "language": "sql",
        "name": "cell19"
      },
      "outputs": [],
      "source": [
        "-- Teardown table and stage created as part of this example\n",
        "DROP TABLE APP_ORDER;\n",
        "DROP STAGE TASTYBYTE_STAGE;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d149c3c7-4a48-446e-a75f-beefc949790b",
      "metadata": {
        "collapsed": false,
        "name": "cell20"
      },
      "source": [
        "### Conclusion\n",
        "In this example, we took a look at how you can load a CSV file from an external stage to process and query the data in your notebook using Snowpark. You can learn more about how to work with your data using Snowpark Python [here](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
