{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "xf5jj4ysk3ppxdxajsmq",
   "authorId": "3290930229076",
   "authorName": "JSOMMERFELD",
   "authorEmail": "jan.sommerfeld@snowflake.com",
   "sessionId": "ac62b46f-8bb1-4920-89fc-893fc6941f02",
   "lastEditTime": 1751831971391
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb8416f-ee57-460f-907a-b9be13125887",
   "metadata": {
    "collapsed": false,
    "name": "_title"
   },
   "source": "# ðŸªµ Snowflake Trail - Step 3: Custom Logging\n\nThis notebooks shows how to set up custom event logging in addition to the standard event-logs from Tasks, Dynamic Tables, etc.\n\nWe will set up event logs for 3 common events that users want to be notified about:\n* Stale Streams\n* Streams stale in <24 hours\n* Overloaded Warehouse (queued queries >10%)"
  },
  {
   "cell_type": "markdown",
   "id": "32c42aad-873e-4610-b551-ea5cff058d1a",
   "metadata": {
    "name": "_3_0_custom_loggers",
    "collapsed": false
   },
   "source": "## 3.0. Custom Loggers for error, warning and info\n* we can call these functions to log events\n* âš ï¸ since the logger-functions are inside the SNOWTRAIL_DEMO database, the events will be logged to the event-table set for this database"
  },
  {
   "cell_type": "code",
   "id": "ba3e1685-a82a-450e-ab70-2e9f1ff3952a",
   "metadata": {
    "language": "sql",
    "name": "create_error_logger_function"
   },
   "outputs": [],
   "source": "--- function to manually log error to event_table\ncreate or replace function SNOWTRAIL_DEMO.OBSERV.ERROR_LOG(MESSAGE varchar)\nreturns VARCHAR\nlanguage PYTHON\nRUNTIME_VERSION = 3.8\nHANDLER = 'run'\nas $$\nimport logging\nlogger = logging.getLogger(\"Snowtrail_logger\")\n\ndef run(MESSAGE):\n  logger.error(MESSAGE)\n  return \"Pipeline Error Logged\"\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f2ed8d5-e708-4857-a22e-447ef54ca034",
   "metadata": {
    "language": "sql",
    "name": "create_warn_logger_function"
   },
   "outputs": [],
   "source": "--- function to manually log warning to event_table\ncreate or replace function SNOWTRAIL_DEMO.OBSERV.WARN_LOG(MESSAGE varchar)\nreturns VARCHAR\nlanguage PYTHON\nRUNTIME_VERSION = 3.8\nHANDLER = 'run'\nas $$\nimport logging\nlogger = logging.getLogger(\"Snowtrail_logger\")\n\ndef run(MESSAGE):\n  logger.warn(MESSAGE)\n  return \"Pipeline Warning Logged\"\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca116653-5d67-4705-8448-cbb27e198571",
   "metadata": {
    "language": "sql",
    "name": "create_info_logger_function"
   },
   "outputs": [],
   "source": "--- function to manually log warning to event_table\ncreate or replace function SNOWTRAIL_DEMO.OBSERV.INFO_LOG(MESSAGE varchar)\nreturns VARCHAR\nlanguage PYTHON\nRUNTIME_VERSION = 3.8\nHANDLER = 'run'\nas $$\nimport logging\nlogger = logging.getLogger(\"Snowtrail_logger\")\n\ndef run(MESSAGE):\n  logger.info(MESSAGE)\n  return \"Pipeline Info Logged\"\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "16e4678c-b4bb-4eb4-80bd-ef2aac575e86",
   "metadata": {
    "collapsed": false,
    "name": "_3_2_Stream_logging"
   },
   "source": "## 3.1. Custom Alert on Streams\n* logging new stale streams as errors\n* logging streams going stale within 24h as warning\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5911730-ccb3-4743-ba5e-7b4e52fa5116",
   "metadata": {
    "language": "sql",
    "name": "create_alert_on_stale_streams"
   },
   "outputs": [],
   "source": "create or replace alert SNOWTRAIL_DEMO.OBSERV.STALE_STREAMS_TO_EVENT_TABLE\nschedule = '60 minute'\ncomment = 'checks all Streams in database'\nif (exists(\n    with \n        GET_STALE_STREAMS as procedure()\n        returns table()\n        language SQL\n        as\n        $$\n        begin    \n            show streams in database;\n            let result resultset := (  \n                select \n                    concat($3,'.',$4,'.',$2) as STREAM_FULL_NAME\n                from \n                    table(result_scan(last_query_id()))\n                where\n                    $11 = 'true'   ---is stale\n                    and $13 >= SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()    -- new since the last Alert run (system function)\n            );\n            return table(result);\n        end;\n        $$\n    call GET_STALE_STREAMS()\n))\n\nthen\n    begin\n        let STALE_STREAMS resultset := (select * from table(result_scan(SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID())));\n        \n        for RECORD in STALE_STREAMS do    \n            let ERROR_MESSAGE string := ('Stream '||RECORD.STREAM_FULL_NAME||' is stale.');\n              \n            select SNOWTRAIL_DEMO.OBSERV.ERROR_LOG(:ERROR_MESSAGE);\n        end for;\nend; "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec29fae-4a0a-4e9f-9a7a-cba3f61703bd",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "resume_alert_on_stale_streams",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "alter alert SNOWTRAIL_DEMO.OBSERV.STALE_STREAMS_TO_EVENT_TABLE resume;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b014ae-d565-4827-9534-a90a187fff6a",
   "metadata": {
    "language": "sql",
    "name": "create_alert_stream_warning",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace alert SNOWTRAIL_DEMO.OBSERV.STREAMS_WARNING_TO_EVENT_TABLE\nschedule = '60 minute'\ncomment = 'checks all Streams in database'\nif (exists(\n    with \n        OLD_STREAMS as procedure()\n        returns table()\n        language SQL\n        as\n        $$\n        begin    \n            show streams in database;\n            \n            let result resultset := (  \n                select \n                    concat($3,'.',$4,'.',$2) as STREAM_FULL_NAME,\n                    timediff(hour, current_timestamp, $13) as STALE_IN_HOURS\n                from \n                    table(result_scan(last_query_id()))\n                where\n                    $11 = 'false'   ---is not yet stale\n                    and STALE_IN_HOURS < 24\n            );\n            return table(result);\n        end;\n        $$    \n    call OLD_STREAMS()\n))\n\nthen\n    begin\n        let ALMOST_STALE_STREAMS resultset := (select * from table(result_scan(SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID())));\n        \n        for RECORD in ALMOST_STALE_STREAMS do    \n            let WARN_MESSAGE string := ('Stream '||RECORD.STREAM_FULL_NAME||' will become stale in '||RECORD.STALE_IN_HOURS||' hours.');\n              \n            select SNOWTRAIL_DEMO.OBSERV.WARN_LOG(:WARN_MESSAGE);\n        end for;\nend; "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325fac6-9d2a-4053-9258-56d08fb02f7f",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "resume_alert_stream_warning"
   },
   "outputs": [],
   "source": [
    "alter alert SNOWTRAIL_DEMO.OBSERV.STREAMS_WARNING_TO_EVENT_TABLE resume;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2181e8-bdba-4ef3-b298-7a4195ea4337",
   "metadata": {
    "collapsed": false,
    "name": "_3_3_warehouse_warning_logs"
   },
   "source": "## 3.2. Custom Alert on Warehouse overload\n\nChecking for all Warehouses in the account."
  },
  {
   "cell_type": "code",
   "id": "ce0f6652-5e5d-4156-b8c2-28a526e2cf40",
   "metadata": {
    "language": "sql",
    "name": "warehouse_load_query"
   },
   "outputs": [],
   "source": "-- see https://docs.snowflake.com/en/sql-reference/functions/warehouse_load_history\n select\n    WAREHOUSE_NAME,\n    START_TIME,\n    AVG_QUEUED_LOAD\nfrom \n    table(SNOWFLAKE.INFORMATION_SCHEMA.WAREHOUSE_LOAD_HISTORY(\n        DATE_RANGE_START => timeadd(hour, -5, current_timestamp)\n    ))\nwhere\n    AVG_QUEUED_LOAD > 0.9\n    --AVG_QUEUED_LOAD < 0.9     -- to test for results if you don't have warehouses with >90% utilization\norder by\n    START_TIME desc\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0fcdde8-84ef-4bb1-afb4-a249d19df82e",
   "metadata": {
    "language": "sql",
    "name": "warehouse_load_alert"
   },
   "outputs": [],
   "source": "-- hourly check on WAREHOUSE_LOAD_HISTORY for queued up queries\n\ncreate or replace alert SNOWTRAIL_DEMO.OBSERV.WAREHOUSE_LOAD_WARN_TO_EVENT_TABLE\nschedule = '60 minute'\ncomment = 'checks Warehouses in this database for overload and logs them as warning to the event table'\nif (exists(\n    select \n        distinct WAREHOUSE_NAME\n    from \n        table(SNOWFLAKE.INFORMATION_SCHEMA.WAREHOUSE_LOAD_HISTORY(\n            DATE_RANGE_START => SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()\n        ))\n    where\n        AVG_QUEUED_LOAD > 0.9\n        and WAREHOUSE_NAME not like 'COMPUTE_SERVICE_WH%'       -- exclude serverless\n    ))\nthen\n    begin\n        let WH_OVERLOAD resultset := (select * from table(result_scan(SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID())));\n        \n        for RECORD in WH_OVERLOAD do    \n            let WARN_MESSAGE string := ('Warehouse '||RECORD.WAREHOUSE_NAME||' was queued up between '||SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()||' and '||current_timestamp()||'.');\n              \n            select SNOWTRAIL_DEMO.OBSERV.WARN_LOG(:WARN_MESSAGE);\n        end for;\n    end; \n;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "193bf9fe-eab0-4fd2-8b75-22ceb1f6e6c8",
   "metadata": {
    "language": "sql",
    "name": "resume_warehouse_load_alert"
   },
   "outputs": [],
   "source": "alter alert SNOWTRAIL_DEMO.OBSERV.WAREHOUSE_LOAD_WARN_TO_EVENT_TABLE resume;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98e2d1d0-27c3-4f63-a0ca-778bb49fb1fc",
   "metadata": {
    "name": "next_steps",
    "collapsed": false
   },
   "source": "...these types of triggers are not so easy to test. But you can still check the Alert_History to see if all alerts ran correctly."
  }
 ]
}
