{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "ks42z7ph6xelsljib7j3",
   "authorId": "6841714608330",
   "authorName": "CHANINN",
   "authorEmail": "chanin.nantasenamat@snowflake.com",
   "sessionId": "8f65d472-7a46-4718-bf41-cf10ebf34c3f",
   "lastEditTime": 1760930557322
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "md_title",
    "collapsed": false
   },
   "source": "# Build Your First Machine Learning Project - Part 4 | `Experiment Tracking`\n\nIn this notebook, we'll demonstrate **experiment tracking** using Snowflake ML's experiment tracking capabilities with the **Bear Species Classification** dataset. We'll train multiple models and compare their performance using Snowflake's built-in experiment tracking features.\n\n### What We'll Cover:\n\n1. **Data Loading and Preparation** - Load and process the bear dataset using Snowpark (`snowflake-snowpark-python`)\n2. **Experiment Setup** - Initialize Snowflake ML experiment tracking (`ExperimentTracking()` from `snowflake-ml-python`)\n3. **Model Training** - Train multiple models as part of hyperparameter tuning with `scikit-learn` using the Random Forest algorithm. Performance are tracked.\n4. **Performance Comparison** - Compare models using tracked metrics\n5. **Model Selection** - Select the best performing model and register with Snowflake Model Registry (`log_model()` from `snowflake-ml-python`)",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "md_setup",
    "collapsed": false
   },
   "source": "## 1. Setup and Data Loading\n\nFirst, let's set up our Snowflake session and check our GPU compute. Next, we'll load the bear dataset.\n",
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "id": "2d8bbdc3-9be3-45f8-b7fe-cb03b08425fc",
   "metadata": {
    "language": "python",
    "name": "py_install_packages"
   },
   "outputs": [],
   "source": "! pip install snowflake-ml-python",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "py_init_session",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nimport streamlit as st\n\n# Get active Snowflake session \nsession = get_active_session()\nst.write(\"‚úÖ Connected using active Snowflake session!\")",
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "code",
   "id": "288ba7b0-90e6-42bf-a9a4-edc9a8095426",
   "metadata": {
    "language": "python",
    "name": "py_warnings"
   },
   "outputs": [],
   "source": "import warnings\n\n# Filter out ResourceWarning\nwarnings.filterwarnings('ignore', category=ResourceWarning)\n\n# Filter out DeprecationWarning\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\n# Filter out UserWarning\nwarnings.filterwarnings('ignore', category=UserWarning)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45106ed5-6480-4847-932f-3031136d5582",
   "metadata": {
    "name": "md_load_data",
    "collapsed": false
   },
   "source": "### Load Data\n\nFinally, we'll load in the Bear data set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "py_load_data",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Load bear dataset from Snowflake\nimport pandas as pd\n\nbear_df = session.table('BEAR').to_pandas()\n\nst.write(\"üìä Bear Dataset Loaded:\")\nst.write(f\"Shape: {bear_df.shape}\")\n\nbear_df",
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "markdown",
   "id": "483c1394-f672-4f08-bd08-9e29c9fe844e",
   "metadata": {
    "name": "md_data_prep",
    "collapsed": false
   },
   "source": "## 2. Data Preparation"
  },
  {
   "cell_type": "markdown",
   "id": "c37709c9-d727-47b6-a112-46b3034ffd89",
   "metadata": {
    "name": "md_prep_features",
    "collapsed": false
   },
   "source": "### Prepare features and target variables"
  },
  {
   "cell_type": "code",
   "id": "b294cc03-c87c-4fed-9730-c9cd19751de1",
   "metadata": {
    "language": "python",
    "name": "py_prep_features"
   },
   "outputs": [],
   "source": "# Prepare features and target\nfrom sklearn.model_selection import train_test_split\n\nX = bear_df.drop(columns=['species', 'id'])\ny = bear_df['species']",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fba817af-73d9-43aa-b29d-47ea40d673be",
   "metadata": {
    "name": "md_missing_data",
    "collapsed": false
   },
   "source": "### Missing data\n\nIt's always good practice to check for missing data."
  },
  {
   "cell_type": "code",
   "id": "ab0d17d1-bdb5-4d9e-99d8-1c2318f084fe",
   "metadata": {
    "language": "python",
    "name": "py_check_missing_data"
   },
   "outputs": [],
   "source": "# Check for missing data\nmissing_features = X.isnull().sum().sum()\nmissing_target = y.isnull().sum()\n\nst.subheader(\"üîç Data Quality Check:\")\nst.write(f\"Missing feature values: `{missing_features}`\")\nst.write(f\"Missing target values: `{missing_target}`\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d642dc47-fb99-47ae-9fe1-7c0404de60e0",
   "metadata": {
    "name": "md_data_split",
    "collapsed": false
   },
   "source": "### Data splitting\n\nHere, we'll split the data to training and test sets using the 80/20 split ratio."
  },
  {
   "cell_type": "code",
   "id": "1c0fbad2-98c4-43a8-be5e-4ab89d3253a6",
   "metadata": {
    "language": "python",
    "name": "py_data_split"
   },
   "outputs": [],
   "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    random_state=42, \n    stratify=y\n)\n\nst.write(\"‚úÖ Data preparation completed!\")\n\nst.subheader(\"üìä Data Split Summary:\")\nst.write(f\"Training set: `{X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)`\")\nst.write(f\"Testing set: `{X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)`\")\nst.write(f\"Number of features: {X_train.shape[1]}\")\n\nst.subheader(\"üéØ Class Distribution:\")\nst.write(f\"Training set: `{y_train.value_counts().sort_index().to_dict()}`\")\nst.write(f\"Testing set: `{y_test.value_counts().sort_index().to_dict()}`\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30b34aa0-163c-42a7-adb9-79ac38e9e135",
   "metadata": {
    "name": "md_feature_scaling",
    "collapsed": false
   },
   "source": "### Feature Scaling\n\nTo prepare our data for model training, we'll apply the following pre-processing:\n- `StandardScaler` for numerical features. This transforms features to have mean=0 and std=1\n- `OneHotEncoder` for categorical features (fur_color, facial_profile, paw_pad_texture). This converts categorical variables into binary columns.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "py_feature_scaling",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Feature scaling and preprocessing\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# Identify numerical and categorical columns\nnumerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X_train.select_dtypes(include=['object']).columns\n\n# Scale numerical features\nscaler = StandardScaler()\nX_train_scaled_num = scaler.fit_transform(X_train[numerical_features])\nX_test_scaled_num = scaler.transform(X_test[numerical_features])\n\n# Handle categorical features\nonehot = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nX_train_scaled_cat = onehot.fit_transform(X_train[categorical_features])\nX_test_scaled_cat = onehot.transform(X_test[categorical_features])\n\n# Get feature names after one-hot encoding and replace spaces with underscores\ncat_feature_names = []\nfor feature, categories in zip(categorical_features, onehot.categories_):\n    for category in categories:\n        cat_feature_names.append(f\"{feature}_{category}\".replace(' ', '_').lower())\n\n# Combine numerical and categorical features\nX_train_scaled = np.hstack([X_train_scaled_num, X_train_scaled_cat])\nX_test_scaled = np.hstack([X_test_scaled_num, X_test_scaled_cat])\n\n# Convert to DataFrame with proper column names\nall_feature_names = list(numerical_features) + cat_feature_names\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=all_feature_names, index=X_train.index)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=all_feature_names, index=X_test.index)\n\nst.write(\"‚úÖ Feature scaling completed!\")\n\nst.subheader(\"üîß Feature Processing:\")\nst.write(f\"Numerical features: `{numerical_features.tolist()}`\")\nst.write(f\"Categorical features: `{categorical_features.tolist()}`\")\n\nst.subheader(\"üìä Scaled Data Dimensions:\")\nst.write(f\"Training features: `{X_train_scaled.shape}`\")\nst.write(f\"Testing features: `{X_test_scaled.shape}`\")\n\n# Display first few encoded feature names\nst.write(\"\\nüè∑Ô∏è First few encoded feature names:\")\nst.write(all_feature_names[:10])\n",
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "markdown",
   "id": "ef7e5b74-e288-4ad2-b08f-9484acb5c54f",
   "metadata": {
    "name": "md_encode_target",
    "collapsed": false
   },
   "source": "### Encode Target Variable\n\nLet's also encode the target variable (Bear species) to numerical values using scikit-learn's `LabelEncoder`.\n- Machine learning models require numerical inputs\n- Each unique bear species will be assigned a unique integer value\n- The encoding preserves the categorical nature of the species while making it suitable for model training"
  },
  {
   "cell_type": "code",
   "id": "803fb8dd-2168-4748-8608-7e127b1ce0c2",
   "metadata": {
    "language": "python",
    "name": "py_encode_target",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.preprocessing import LabelEncoder\n\n# Encode target variable\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf3c51b5-5d4d-4f40-bddc-b74a910bded3",
   "metadata": {
    "language": "python",
    "name": "py_y_train_encoded"
   },
   "outputs": [],
   "source": "y_train_encoded",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "037ed9bc-4b06-4274-8841-33a9ffb3fe53",
   "metadata": {
    "language": "python",
    "name": "py_y_test_encoded"
   },
   "outputs": [],
   "source": "y_test_encoded",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6857467c-3c32-43ea-a20f-b10f11813286",
   "metadata": {
    "name": "md_write_test_data",
    "collapsed": false
   },
   "source": "### Write Test Data to Table\n\nLet's now write the test set data (stored in the `X_test_scaled` variable) to a Snowflake table `BEAR_TEST_DATA`"
  },
  {
   "cell_type": "code",
   "id": "0f503027-72d6-4d92-b0d8-cdfebedfe0c3",
   "metadata": {
    "language": "python",
    "name": "py_write_test_data"
   },
   "outputs": [],
   "source": "# Create a copy of X_test_scaled\ntest_df = X_test_scaled.copy()\n\n# Add the encoded target variable\ntest_df['ACTUAL_SPECIES'] = y_test_encoded\n\n# Convert to Snowpark DataFrame and write to table\nsnowpark_df = session.create_dataframe(test_df)\nsnowpark_df.write.mode(\"overwrite\").save_as_table(\"CHANINN_DEMO_DATA.PUBLIC.BEAR_TEST_DATA\")\n\nst.write(\"‚úÖ Data successfully saved to BEAR_TEST_DATA table!\")\nst.write(f\"Number of rows: {len(test_df)}\")\nst.write(f\"Number of columns: {len(test_df.columns)}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "md_exp_tracking",
    "collapsed": false
   },
   "source": "## 3. Experiment Tracking Setup\n\nNow let's set up our experiment tracking using Snowflake ML's experiment tracking capabilities. This will allow us to systematically log and compare different models and their hyperparameters.\n\nWe'll start out by creating the experiment tracker with `ExperimentTracking` from the Snowflake ML package.",
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "py_exp_tracking",
    "language": "python"
   },
   "outputs": [],
   "source": "from snowflake.ml.experiment.experiment_tracking import ExperimentTracking\n\n# Create ExperimentTracking\nexp = ExperimentTracking(session=session)\n\n# Set Experiment Name\nexperiment_name = \"Bear_Classification_Experiment\"\nexp.set_experiment(experiment_name)\n\nst.write(f\"‚úÖ Experiment Tracking Initialized: `{experiment_name}`\")",
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "id": "b792e620-6618-4e80-890b-1d36b95ec601",
   "metadata": {
    "language": "python",
    "name": "py_baseline_model"
   },
   "outputs": [],
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef\nfrom datetime import datetime\n\n# Define Hyperparameters ---\nparams = {\n    \"n_estimators\": 100,\n    \"max_depth\": 3,\n    \"min_samples_leaf\": 5,\n    'max_features': 'sqrt',\n    \"random_state\": 42\n}\n\n# Create unique run name with timestamp\nrun_name = f\"bear_baseline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n# Train, Evaluate and Log Model\nwith exp.start_run(run_name):\n    # Log hyperparameters\n    exp.log_params(params)\n\n    # Train model\n    model = RandomForestClassifier(**params)\n    model.fit(X_train_scaled, y_train_encoded)\n\n    # Predict\n    y_pred = model.predict(X_test_scaled)\n\n    # Calculate metrics\n    acc = accuracy_score(y_test_encoded, y_pred)\n    precision = precision_score(y_test_encoded, y_pred, average='macro')\n    recall = recall_score(y_test_encoded, y_pred, average='macro')\n    mcc = matthews_corrcoef(y_test_encoded, y_pred)\n\n    # Log metrics\n    exp.log_metric(\"accuracy\", acc)\n    exp.log_metric(\"precision\", precision)\n    exp.log_metric(\"recall\", recall)\n    exp.log_metric(\"mcc\", mcc)\n\n    # Display results\n    st.write(\"üìä Model Performance:\")\n    st.write(f\"- Accuracy: `{acc:.4f}`\")\n    st.write(f\"- Precision: `{precision:.4f}`\")\n    st.write(f\"- Recall: `{recall:.4f}`\")\n    st.write(f\"- MCC: `{mcc:.4f}`\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "md_hyperparameter_tuning",
    "collapsed": false
   },
   "source": "## 4. Hyperparameter Tuning\n\nNow let's analyze the results from our Random Forest hyperparameter tuning experiments. We'll retrieve the logged metrics and examine the tuning process in detail.\n",
   "id": "ce110000-1111-2222-3333-ffffff000013"
  },
  {
   "cell_type": "code",
   "id": "c9fe2a98-f00a-4757-bb32-dcec2a58877a",
   "metadata": {
    "language": "python",
    "name": "py_hyperparameter_tuning"
   },
   "outputs": [],
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef\nfrom datetime import datetime\nimport itertools\nimport pandas as pd\n\n# Define hyperparameter grid\nparam_grid = {\n    \"n_estimators\": [100, 200],\n    \"max_depth\": [3, 5],\n    \"min_samples_leaf\": [1, 2, 5],\n    \"max_features\": ['sqrt', 'log2']\n}\n\n# Initialize list to store results\nresults = []\n\n# Generate all combinations of parameters\nparam_combinations = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n\n# Train models with different parameters\nfor params in param_combinations:\n    # Add random state to params\n    params['random_state'] = 42\n    \n    # Create unique run name with timestamp and params summary\n    run_name = f\"RF_tune_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n    with exp.start_run(run_name):\n        # Log hyperparameters\n        exp.log_params(params)\n\n        # Train model\n        model = RandomForestClassifier(**params)\n        model.fit(X_train_scaled, y_train_encoded)\n\n        # Predict\n        y_pred = model.predict(X_test_scaled)\n\n        # Calculate metrics\n        acc = accuracy_score(y_test_encoded, y_pred)\n        precision = precision_score(y_test_encoded, y_pred, average='macro')\n        recall = recall_score(y_test_encoded, y_pred, average='macro')\n        mcc = matthews_corrcoef(y_test_encoded, y_pred)\n\n        # Log metrics\n        exp.log_metric(\"accuracy\", acc)\n        exp.log_metric(\"precision\", precision)\n        exp.log_metric(\"recall\", recall)\n        exp.log_metric(\"mcc\", mcc)\n\n        # Store results\n        results.append({\n            'run_name': run_name,\n            'n_estimators': params['n_estimators'],\n            'max_depth': params['max_depth'],\n            'min_samples_leaf': params['min_samples_leaf'],\n            'max_features': params['max_features'],\n            'accuracy': acc,\n            'precision': precision,\n            'recall': recall,\n            'mcc': mcc\n        })\n\n        st.write(f\"Parameters: {params}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d906423e-823c-49b5-aa10-48467f25075e",
   "metadata": {
    "name": "md_analyze_results",
    "collapsed": false
   },
   "source": "Now that we've run the hyperparameter tuning, let's analyze the results to find the best performing model."
  },
  {
   "cell_type": "code",
   "id": "c1605e27-8e55-4f01-97ae-2b26e864a24c",
   "metadata": {
    "language": "python",
    "name": "py_analyze_results",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create DataFrame from results\nresults_df = pd.DataFrame(results)\n\n# Display summary statistics\nst.write(\"üìä Model Performance Summary:\")\nst.dataframe(results_df.style.highlight_max(subset=['accuracy', 'precision', 'recall', 'mcc'], color=\"green\"))\n\n# Display best performing configuration\nbest_model = results_df.loc[results_df['accuracy'].idxmax()]\n\nst.subheader(\"üèÜ Best Model Configuration:\")\nst.write(\"Learning Algorithm: `Random Forest`\")\nst.write(f\"Accuracy: `{best_model['accuracy']:.4f}`\")\nst.write(f\"Precision: `{best_model['precision']:.4f}`\")\nst.write(f\"Recall: `{best_model['recall']:.4f}`\")\nst.write(f\"MCC: `{best_model['mcc']:.4f}`\")\nst.write(f\"Learning Parameters:\")\nst.write(f\"- n_estimators: `{best_model['n_estimators']}`\")\nst.write(f\"- max_depth: `{best_model['max_depth']}`\")\nst.write(f\"- min_samples_leaf: `{best_model['min_samples_leaf']}`\")\nst.write(f\"- max_features: `{best_model['max_features']}`\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "md_model_registry",
    "collapsed": false
   },
   "source": "## 5. Model Registry\n\nLet's now register the best model to Snowflake's Model Registry for deployment and management.\n",
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "markdown",
   "id": "1a21edea-b706-496c-8875-5e74903f1745",
   "metadata": {
    "name": "md_train_final",
    "collapsed": false
   },
   "source": "### Train Final Model with Best Parameters\n\nNow that we've identified the best performing model configuration from our hyperparameter tuning experiments, let's train the final model using these optimal parameters:\n\n- Number of estimators: 100\n- Maximum depth: 5\n- Minimum samples per leaf: 2\n- Maximum features: sqrt"
  },
  {
   "cell_type": "code",
   "id": "7a4f36a0-2543-4c70-8c3b-bba10657633e",
   "metadata": {
    "language": "python",
    "name": "py_train_final",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Get best model configuration from previous results\nbest_params = {\n    'n_estimators': int(best_model['n_estimators']),\n    'max_depth': int(best_model['max_depth']),\n    'min_samples_leaf': int(best_model['min_samples_leaf']),\n    'max_features': best_model['max_features'],\n    'random_state': 42\n}\n\n# Train the best model\nfinal_model = RandomForestClassifier(**best_params)\nfinal_model.fit(X_train_scaled, y_train_encoded)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed299b89-02b1-4fff-beb1-24ed2a062340",
   "metadata": {
    "language": "python",
    "name": "py_best_params"
   },
   "outputs": [],
   "source": "best_params",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d13e67a-1c90-41a4-855d-2d92aef14862",
   "metadata": {
    "name": "md_register_model",
    "collapsed": false
   },
   "source": "### Register Best Model\n\nNow we'll register our best-performing Random Forest model in Snowflake's Model Registry. "
  },
  {
   "cell_type": "code",
   "id": "b76971c5-ae00-459f-a35e-98ddbe8f99c0",
   "metadata": {
    "language": "python",
    "name": "py_register_model"
   },
   "outputs": [],
   "source": "# Create model registry instance\nfrom snowflake.ml.registry import Registry\nfrom datetime import datetime\nimport warnings\n\n# Temporarily suppress warnings\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\nregistry = Registry(session)\n\n# Clean the column names by replacing spaces with underscores\nX_train_clean = X_train_scaled.copy()\nX_train_clean.columns = X_train_clean.columns.str.replace(' ', '_')\n\n# Register model\nmodel_name = \"BEAR_SPECIES_CLASSIFIER\"\nmodel_version = f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\nmodel_ref = registry.log_model(\n    model=final_model,\n    model_name=model_name,\n    version_name=model_version,\n    sample_input_data=X_train_clean.head(5),\n    metrics={\n        'accuracy': float(best_model['accuracy']),\n        'precision': float(best_model['precision']),\n        'recall': float(best_model['recall']),\n        'mcc': float(best_model['mcc'])\n    },\n    options={\n        \"case_sensitive\": True,\n        \"min_positive_value\": 1e-10  # Add small constant to prevent log(0)\n    },\n    comment=\"Best performing Random Forest model from hyperparameter tuning\"\n)\n\n# Reset warnings to default\nwarnings.resetwarnings()\n\nst.write(\"‚úÖ Model successfully registered!\")\nst.write(f\"Model Name: `{model_name}`\")\nst.write(f\"Version: `{model_version}`\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "035d4d87-6e43-49f4-8815-f6d6618e18d2",
   "metadata": {
    "name": "md_show_models",
    "collapsed": false
   },
   "source": "### Show Models in Registry"
  },
  {
   "cell_type": "code",
   "id": "99dc166c-5717-4083-b1c8-06b9b8372e23",
   "metadata": {
    "language": "sql",
    "name": "sql_show_models"
   },
   "outputs": [],
   "source": "SHOW MODELS",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e98d739a-fd77-4e18-b1ac-c1d2d52aa8ce",
   "metadata": {
    "language": "python",
    "name": "py_show_models"
   },
   "outputs": [],
   "source": "registry.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cdddbcd4-767b-40f9-ba03-384a0db4131e",
   "metadata": {
    "name": "md_show_model_versions",
    "collapsed": false
   },
   "source": "### Show Available Versions in a Model"
  },
  {
   "cell_type": "code",
   "id": "6036d11b-a75b-4812-b9ec-0e4bb28967a1",
   "metadata": {
    "language": "sql",
    "name": "sql_show_model_versions"
   },
   "outputs": [],
   "source": "SHOW VERSIONS IN MODEL bear_species_classifier;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "06ebc9c4-f1d8-4400-83b4-303366798cb2",
   "metadata": {
    "name": "md_show_model_functions",
    "collapsed": false
   },
   "source": "### Show Available Functions in a Model"
  },
  {
   "cell_type": "code",
   "id": "28889eaa-7dc7-414b-a1fd-a357b14f5b14",
   "metadata": {
    "language": "sql",
    "name": "sql_show_model_functions"
   },
   "outputs": [],
   "source": "SHOW FUNCTIONS IN MODEL bear_species_classifier",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "065e2e31-185f-4846-ac8b-febfb9d21c05",
   "metadata": {
    "name": "md_deploy_model",
    "collapsed": false
   },
   "source": "## Deploy the Model as a Service"
  },
  {
   "cell_type": "code",
   "id": "2c8bd84d-c676-4495-ba1c-31a9ee32d668",
   "metadata": {
    "language": "python",
    "name": "py_deploy_model"
   },
   "outputs": [],
   "source": "# First drop existing service using SQL through session\nsession.sql(\"DROP SERVICE IF EXISTS bear_rf_classifier\").collect()\n\n# Deploy to a GPU compute pool on SPCS\nmodel_ref.create_service(\n    service_name=\"bear_rf_classifier\",\n    service_compute_pool=\"system_compute_pool_cpu\",\n    ingress_enabled=True,\n    gpu_requests=None\n)\n\nst.write(\"‚úÖ Model service created successfully!\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "160f3b4d-5a0d-466d-a086-cbe9af0acc0b",
   "metadata": {
    "name": "md_show_service_endpoints",
    "collapsed": false
   },
   "source": "### Show Service Endpoints\n\nLet's examine the endpoints exposed by our deployed model."
  },
  {
   "cell_type": "code",
   "id": "6bb93be6-826d-4d5b-b9ec-042748551a21",
   "metadata": {
    "language": "sql",
    "name": "sql_show_services"
   },
   "outputs": [],
   "source": "SHOW SERVICES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a520180-e660-40b0-a774-911e0d634a98",
   "metadata": {
    "language": "sql",
    "name": "sql_show_service_endpoints"
   },
   "outputs": [],
   "source": "SHOW ENDPOINTS IN SERVICE bear_rf_classifier;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b882799-358d-49c1-995c-df0432bf447b",
   "metadata": {
    "name": "md_model_inference",
    "collapsed": false
   },
   "source": "### Perform Model Inference\n\nNow that our model is deployed as a service, we can use it to make predictions on new data. \n\nHere's what we're doing:\n- Query the `BEAR_TEST_DATA` table\n- Pass the features through our deployed model\n- Get predictions for bear species classification using the `PREDICT()` function"
  },
  {
   "cell_type": "code",
   "id": "093cb437-2fd8-48ae-84f2-5aa12ebe44c4",
   "metadata": {
    "language": "sql",
    "name": "py_model_inference",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT\n  BEAR_RF_CLASSIFIER ! PREDICT(\n    \"body_mass_kg\",\n    \"shoulder_hump_height_cm\",\n    \"claw_length_cm\",\n    \"snout_length_cm\",\n    \"forearm_circumference_cm\",\n    \"ear_length_cm\",\n    \"fur_color_black\",\n    \"fur_color_blackish_brown\",\n    \"fur_color_blond\",\n    \"fur_color_brown\",\n    \"fur_color_cinnamon\",\n    \"fur_color_dark_brown\",\n    \"fur_color_grizzled\",\n    \"fur_color_light_brown\",\n    \"fur_color_medium_brown\",\n    \"fur_color_reddish_brown\",\n    \"facial_profile_dished\",\n    \"facial_profile_straight\",\n    \"paw_pad_texture_rough\",\n    \"paw_pad_texture_smooth\"\n  ) AS predicted_species\nFROM\n  CHANINN_DEMO_DATA.PUBLIC.BEAR_TEST_DATA\nLIMIT\n  5;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33eb589b-b062-41cf-b274-462a7cc5ec8c",
   "metadata": {
    "name": "md_avg_abb",
    "collapsed": false
   },
   "source": "### Average Values of Features"
  },
  {
   "cell_type": "code",
   "id": "984cc764-97b3-4556-aa7c-6035c4dfb01b",
   "metadata": {
    "language": "sql",
    "name": "sql_avg_abb"
   },
   "outputs": [],
   "source": "SELECT\n  AVG(\"body_mass_kg\") AS \"body_mass_kg\",\n  AVG(\"shoulder_hump_height_cm\") AS \"shoulder_hump_height_cm\",\n  AVG(\"claw_length_cm\") AS \"claw_length_cm\",\n  AVG(\"snout_length_cm\") AS \"snout_length_cm\",\n  AVG(\"forearm_circumference_cm\") AS \"forearm_circumference_cm\",\n  AVG(\"ear_length_cm\") AS \"ear_length_cm\",\n\n  -- Fur Color Proportions\n  AVG(CASE WHEN \"fur_color\" = 'Black' THEN 1 ELSE 0 END) AS \"fur_color_black\",\n  AVG(CASE WHEN \"fur_color\" = 'Blackish-Brown' THEN 1 ELSE 0 END) AS \"fur_color_blackish_brown\",\n  AVG(CASE WHEN \"fur_color\" = 'Blond' THEN 1 ELSE 0 END) AS \"fur_color_blond\",\n  AVG(CASE WHEN \"fur_color\" = 'Brown' THEN 1 ELSE 0 END) AS \"fur_color_brown\",\n  AVG(CASE WHEN \"fur_color\" = 'Cinnamon' THEN 1 ELSE 0 END) AS \"fur_color_cinnamon\",\n  AVG(CASE WHEN \"fur_color\" = 'Dark Brown' THEN 1 ELSE 0 END) AS \"fur_color_dark_brown\",\n  AVG(CASE WHEN \"fur_color\" = 'Grizzled' THEN 1 ELSE 0 END) AS \"fur_color_grizzled\",\n  AVG(CASE WHEN \"fur_color\" = 'Light Brown' THEN 1 ELSE 0 END) AS \"fur_color_light_brown\",\n  AVG(CASE WHEN \"fur_color\" = 'Medium Brown' THEN 1 ELSE 0 END) AS \"fur_color_medium_brown\",\n  AVG(CASE WHEN \"fur_color\" = 'Reddish-Brown' THEN 1 ELSE 0 END) AS \"fur_color_reddish_brown\",\n\n  -- Facial Profile Proportions\n  AVG(CASE WHEN \"facial_profile\" = 'Dished' THEN 1 ELSE 0 END) AS \"facial_profile_dished\",\n  AVG(CASE WHEN \"facial_profile\" = 'Straight' THEN 1 ELSE 0 END) AS \"facial_profile_straight\",\n\n  -- Paw Pad Texture Proportions\n  AVG(CASE WHEN \"paw_pad_texture\" = 'Rough' THEN 1 ELSE 0 END) AS \"paw_pad_texture_rough\",\n  AVG(CASE WHEN \"paw_pad_texture\" = 'Smooth' THEN 1 ELSE 0 END) AS \"paw_pad_texture_smooth\"\nFROM\n  CHANINN_DEMO_DATA.PUBLIC.BEAR\nWHERE\n  \"species\" ILIKE '%American Black Bear%';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24f71e59-7f29-493c-a1d2-d437642cd164",
   "metadata": {
    "name": "md_resources",
    "collapsed": false
   },
   "source": "## Resources\n\nDive deeper into the topics mentioned in this notebook with these great articles:\n- [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/overview)\n- [Python APIs for Snowflake ML](https://docs.snowflake.com/en/developer-guide/snowflake-ml/snowpark-ml)\n- [Snowflake ML: End-to-End Machine Learning](https://docs.snowflake.com/en/developer-guide/snowflake-ml/overview)"
  }
 ]
}