{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "notebookId": "64zd7ttelodtqqcazn7c",
      "authorId": "6841714608330",
      "authorName": "CHANINN",
      "authorEmail": "chanin.nantasenamat@snowflake.com",
      "sessionId": "8e215a71-b698-4cd5-8bdb-64324d68cd7e",
      "lastEditTime": 1760806287404
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb7a29c7-92eb-4d12-b8cd-d81075f6e7b4",
      "metadata": {
        "name": "md_title",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Build Your First Machine Learning Project - Part 2 | `Exploratory Data Analysis`\n\nIn this notebook, we'll explore the Bear data set, performing summary statistics, and data visualization. We'll also leverage Streamlit to add interactivity to the data visualization.\n\n### What We'll Cover:\n\n1. **Data Loading and Preparation** - Load the bear dataset and prepare it for analysis using Snowpark (`snowflake-snowpark-python`)\n2. **Basic Statistics** - Calculate and visualize summary statistics of the dataset\n3. **Feature Distribution Analysis** - Explore the distribution of individual features across different bear species with `Altair` and `Streamlit`\n4. **Correlation Analysis** - Investigate relationships between numeric features using correlation heatmaps with `Altair` and `Streamlit`\n5. **Feature Relationships** - Visualize relationships between pairs of features using interactive scatter plots with `Altair` and `Streamlit`\n6. **Categorical Analysis** - Examine the distribution of categorical features including species classification with `Altair` and `Streamlit`\n\n"
    },
    {
      "cell_type": "markdown",
      "id": "862d87e7-c152-4b25-b094-ade3a2d9a2e8",
      "metadata": {
        "name": "md_data_operations",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Data Operations\n\nWe'll start off by loading and preparing the bear data set."
    },
    {
      "cell_type": "markdown",
      "id": "623130bf-a2bc-4c09-b387-edec0b100ef7",
      "metadata": {
        "name": "md_load_data",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Load data\n\nIn Part 1, we've retrieved, prepared and wrote the Bear data to Snowflake and here we'll proceed to loading the data by reading it from a Snowflake table."
    },
    {
      "cell_type": "markdown",
      "id": "a7453e7a-a030-490e-b36e-50d5da6c8ee7",
      "metadata": {
        "name": "md_sql_data",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Load data via SQL query\n\nPreviously, we've saved it to `CHANIN_DEMO_DATA.PUBLIC.BEAR` and therefore we'll query the data with the following SQL statement:"
    },
    {
      "cell_type": "code",
      "id": "676033c3-95e6-40d0-b661-f0ab9240402d",
      "metadata": {
        "language": "sql",
        "name": "sql_data",
        "resultVariableName": "dataframe_1"
      },
      "outputs": [],
      "source": "SELECT * FROM CHANINN_DEMO_DATA.PUBLIC.BEAR",
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "id": "11efd04f-b4bc-43d0-b60c-945c8369418f",
      "metadata": {
        "name": "md_py_data",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Load data via Python statement\n\nWe can also use the same SQL statement inside `pd.read_snowflake()`."
    },
    {
      "cell_type": "code",
      "id": "9e478fe0-0ef3-4ecf-9062-371857c103b4",
      "metadata": {
        "language": "python",
        "name": "py_data"
      },
      "outputs": [],
      "source": "from snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\n# Read data from Snowflake table using Snowpark\ndf_snowpark = session.table(\"CHANINN_DEMO_DATA.PUBLIC.BEAR\")\n\n# Convert to pandas for compatibility with visualization libraries\ndf = df_snowpark.to_pandas()\ndf",
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "id": "86eceb6b-fe20-4eca-b2b9-70a264fe8829",
      "metadata": {
        "name": "md_data_preparation",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Data Preparation\n\nIn preparation for forthcoming plots that require numeric data for visualizations, we'll select only numeric columns from the DataFrame using `select_dtypes()`."
    },
    {
      "cell_type": "code",
      "id": "405c3cfc-41f9-4509-8089-e1f59ccce8a6",
      "metadata": {
        "language": "python",
        "name": "py_data_preparation"
      },
      "outputs": [],
      "source": "# Select only numeric columns from the DataFrame\nnumeric_df = df.select_dtypes(include=['float64', 'int64'])\n\nnumeric_df",
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "id": "2bbf4e2b-7d4f-4a93-99df-66b235f841db",
      "metadata": {
        "name": "md_eda",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Exploratory Data Analysis\n\nExploratory Data Analysis (EDA) is the essential first step in any data project, where you get the chance to become familiar with the data by performing an open-ended exploration of the data. \n\nThis is achieved by performing summary statistics and data visualization to uncover patterns, spot anomalies, and identify relationships between variables, which helps you make sense of its key characteristics and prepare it for more complex tasks."
    },
    {
      "cell_type": "markdown",
      "id": "c290ac7d-21c1-452f-86f2-b50a0c9101e0",
      "metadata": {
        "name": "md_feature_distribution",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Feature Distribution\nLet's start by exploring the distribution of individual features and see how they are distributed across different bear species.\n\nWe'll perform this in 2 implementations:\n1. Traditional script-based approach - Features to visualize can be hard-coded\n1. Interactive data app - You can select feature to visualize\n"
    },
    {
      "cell_type": "code",
      "id": "02e63e2d-19e9-49b2-ba8d-5e2645eea37c",
      "metadata": {
        "language": "python",
        "name": "py_feature_distribution",
        "title": "py_feature_distribution"
      },
      "outputs": [],
      "source": "import altair as alt\nalt.renderers.enable(\"mimetype\")\n\n# Create feature distribution plots\nprint(\"--------------------\")\nprint(\"Feature Distributions\")\nprint(\"--------------------\")\n\nnumeric_cols = numeric_df.columns\n\n# Manually specify features by changing the index number\nfeature = numeric_cols[0]\n\nchart = alt.Chart(df).mark_bar().encode(\n    alt.X(f\"{feature}:Q\", bin=True),\n    y='count()',\n    color=alt.Color('species:N', scale=alt.Scale(scheme='category10'))\n).properties(\n    height=380,\n    title=f\"Distribution of {feature} by Class\"\n)\nchart",
      "execution_count": 7
    },
    {
      "id": "8c7a2b34-e423-4c44-9261-e0cfacf3fae4",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import altair as alt\nalt.renderers.enable(\"mimetype\")\n\n# Create feature distribution plots\nprint(\"--------------------\")\nprint(\"Feature Distributions\")\nprint(\"--------------------\")\n\nnumeric_cols = numeric_df.columns\n\n# Manually specify features by changing the index number\nfeature = numeric_cols[0]\n\nchart = alt.Chart(df).mark_bar().encode(\n    alt.X(f\"{feature}:Q\", bin=True),\n    y='count()',\n    color=alt.Color('species:N', scale=alt.Scale(scheme='category10'))\n).properties(\n    height=380,\n    title=f\"Distribution of {feature} by Class\"\n)\nchart",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b3951a10-7fc1-4b51-acea-9b06f62a5f05",
      "metadata": {
        "name": "md_correlation",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Feature Correlations\n\nNext, we're going to get a bird's-eye view of how all our numeric features relate to each other at once. Doing this helps us quickly find the most interesting relationships to explore in more detail.\n\n"
    },
    {
      "cell_type": "markdown",
      "id": "20fa9d93-a64a-4726-a44f-19b8c6e3977e",
      "metadata": {
        "name": "md_correlation_2",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Correlation matrix\n\nFirst, we'll calculate a correlation matrix. This is just a table that shows the correlation coefficient (a value from -1 to +1) between every possible pair of our numeric features. A value of 1 means a perfect positive relationship, -1 means a perfect negative relationship, and 0 means no linear relationship."
    },
    {
      "cell_type": "code",
      "id": "9560ac7f-9b96-4235-87c3-fb5d8e16de83",
      "metadata": {
        "language": "python",
        "name": "py_heatmap"
      },
      "outputs": [],
      "source": "# Correlation heatmap\nprint(\"--------------------\")\nprint(\"Feature Correlations\")\nprint(\"--------------------\")\n\ncolor_option = ['blueorange', 'spectral', 'viridis']\n# More color schemes at https://vega.github.io/vega/docs/schemes/\n\ncorr_matrix = numeric_df.corr()\n\ncorr_data = (\n    corr_matrix\n    .stack()\n    .reset_index(name='value')\n    .rename(columns={'level_0': 'index', 'level_1': 'variable'})\n)\n\ncorr_chart = alt.Chart(corr_data).mark_rect().encode(\n    x=alt.X('index:N', sort=None),\n    y=alt.Y('variable:N', sort=None),\n    color=alt.Color('value:Q', scale=alt.Scale(scheme=color_option[0])),\n    tooltip=[alt.Tooltip('index:N'), alt.Tooltip('variable:N'), alt.Tooltip('value:Q')]\n).properties(\n    width=400,\n    title=\"Correlation Heatmap\"\n)\ncorr_chart",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "3d5dc868-a7ee-4b02-a71c-6779ac668f79",
      "metadata": {
        "name": "my_feature_relationship",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Feature Relationships\n\nAfter examining individual feature distributions and correlations between features, let's explore specific relationships between pairs of features in more detail. This visualization allows us to:\n\n- See how different numeric features relate to each other\n- Identify potential patterns or clusters by bear species\n- Spot any outliers or unusual relationships in the data\n\nThe scatter plot below shows the relationship between two selected numeric features, with points colored by bear species. This helps us understand how different bear species may cluster or separate based on their physical characteristics."
    },
    {
      "cell_type": "code",
      "id": "4b31c7c1-9e86-4638-9160-2847ba702e19",
      "metadata": {
        "language": "python",
        "name": "py_feature_relationship",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "# Scatter plot for feature relationships\nprint(\"--------------------\")\nprint(\"Feature Relationships\")\nprint(\"--------------------\")\n\n# Manually changing the index value\nx_axis = numeric_cols[0]\ny_axis = numeric_cols[1]\n\nscatter = alt.Chart(df).mark_circle().encode(\n    x=f'{x_axis}:Q',\n    y=f'{y_axis}:Q',\n    color='species:N',\n    tooltip=[f'{x_axis}:Q', f'{y_axis}:Q', 'Species:N']\n).properties(\n    width=380,\n    height=380,\n    title=f\"{x_axis} vs {y_axis} by Class\"\n)\n\nscatter",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "10d551a6-5440-4d2f-948b-39533d6fa192",
      "metadata": {
        "name": "md_class_distribution",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Species Class Distribution\n\nLet's examine the distribution of bear species in our dataset. This visualization will show us:\n\n- The number of samples for each bear species\n- Whether our dataset is balanced or imbalanced across different species\n- The relative proportions of each species in our dataset\n\nThis information is crucial for understanding our data composition and potential biases that could affect our analysis.\n"
    },
    {
      "cell_type": "code",
      "id": "37b7cbcd-e370-48d9-9bc4-18a15cd4f2bb",
      "metadata": {
        "language": "python",
        "name": "py_class_distribution",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "# Class distribution\nprint(\"--------------------\")\nprint(\"Species Class Distribution\")\nprint(\"--------------------\")\n\nclass_dist = alt.Chart(df).mark_bar().encode(\n    x='species:N',\n    y='count()',\n    color='species:N'\n).properties(\n    width=400,\n    height=400,\n    title=\"Distribution of Bear Classes\"\n)\nclass_dist",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f2d15f22-6e17-4d22-8155-7801c6c2afee",
      "metadata": {
        "name": "md_resources",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Resources\nIf you'd like to take a deeper dive into Snowpark pandas:\n- [Altair User Guide](https://altair-viz.github.io/user_guide/data.html)\n- [pandas on Snowflake](https://docs.snowflake.com/en/developer-guide/snowpark/python/pandas-on-snowflake)\n- [Snowpark pandas API](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/modin/index)\n- [YouTube Playlist on Snowflake Notebooks](https://www.youtube.com/watch?v=YB1B6vcMaGE&list=PLavJpcg8cl1Efw8x_fBKmfA2AMwjUaeBI)"
    }
  ]
}
