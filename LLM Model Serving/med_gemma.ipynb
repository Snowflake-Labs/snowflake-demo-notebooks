{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6dce41-4956-447b-84f5-1e5eb6c74454",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": [
    "# Log and serve Huggingface model\n",
    "This notebook provides an example of logging and serving a Huggingface transformers model with `text-genration` task.\n",
    "\n",
    "\n",
    "## To read about Model Serving at Snowflake\n",
    "Documentation: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0503b-2b9b-4b4c-b57b-3b8f72a7d9f6",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowflake-ml-python==1.15.0\n"
     ]
    }
   ],
   "source": [
    "from snowflake.ml import version\n",
    "from snowflake import snowpark\n",
    "from snowflake.ml.registry import registry as registry_module\n",
    "from snowflake.ml.model import openai_signatures\n",
    "\n",
    "print(f\"snowflake-ml-python=={version.VERSION}\")\n",
    "\n",
    "registry = registry_module.Registry(\n",
    "    session=session,\n",
    ")\n",
    "\n",
    "# make sure to be on `snowflake-ml-python>=1.13.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7a225-ad7a-45d4-b901-0058ad174524",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "### Note: The notebook requires an EAI to download files from Huggingface\n",
    "This featuer lets us log a large model without requiring GPU\n",
    "\n",
    "Keep a lookout for a new API in `HuggingFacePipelineModel.log_model_and_create_service()` (to be released in snowflake-ml-python>=1.15.0)\n",
    "which logs the model remotely wihthout having to download the HF model locally. This feature doesn't require EAI to HuggingFace.\n",
    "\n",
    "For now we are downloading the model weights locally using `download_snapshot=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf74c9-6f8d-47db-8ca7-76b8c3e6999a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2938de9abcc04fd5b9a06720b2fe81c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a01bb0086445f6b1cd269aeb0e6efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6c7987394d47bd8c97be8a5ab50b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4269eefcde48199ecec3f677f9d498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a66ffe1a554b44a68db2bbe99b05ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839404a1e6d84df89c760a10ae010362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e0e9bc2c7b44cdad21c5241668de1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/4.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b6b74f5d764909a2217cfbfa4f6b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faed93cbdb274776a07650befdca3b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c703b7b30e4628a90f18b54b0fce0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4cfaf7fbf4434c9146315ee2b49d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4f00e05daa4fd99eb24941a5671559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164df4f7eff04e2abb37841fe568a349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae824f0f2bf4e77a912ea2a504a03fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47103f7d0fb64112a5144c5c07826629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.model.models.huggingface_pipeline.HuggingFacePipelineModel at 0x3741421d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: this requires an EAI to download files from Huggingface\n",
    "# This feature lets us log a large model without requiring GPU\n",
    "\n",
    "# import os\n",
    "from snowflake.ml.model.models import huggingface_pipeline\n",
    "\n",
    "\n",
    "model = huggingface_pipeline.HuggingFacePipelineModel(\n",
    "    model=\"google/medgemma-4b-it\",\n",
    "    task=\"text-generation\",\n",
    "    # TODO: provide token if the model is gated\n",
    "    # token=os.getenv(\"HF_TOKEN\"),\n",
    "    # token=\"hf_...\",\n",
    "    download_snapshot=True,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45cd4c60-d7a6-411b-b495-0769ce310c1b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mREADME.md\u001b[m\u001b[m                        \u001b[35mmodel.safetensors.index.json\u001b[m\u001b[m\n",
      "\u001b[35madded_tokens.json\u001b[m\u001b[m                \u001b[35mpreprocessor_config.json\u001b[m\u001b[m\n",
      "\u001b[35mchat_template.jinja\u001b[m\u001b[m              \u001b[35mprocessor_config.json\u001b[m\u001b[m\n",
      "\u001b[35mconfig.json\u001b[m\u001b[m                      \u001b[35mspecial_tokens_map.json\u001b[m\u001b[m\n",
      "\u001b[35mgeneration_config.json\u001b[m\u001b[m           \u001b[35mtokenizer.json\u001b[m\u001b[m\n",
      "\u001b[35mmodel-00001-of-00002.safetensors\u001b[m\u001b[m \u001b[35mtokenizer.model\u001b[m\u001b[m\n",
      "\u001b[35mmodel-00002-of-00002.safetensors\u001b[m\u001b[m \u001b[35mtokenizer_config.json\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# list the directory where the model files are downloaded\n",
    "! ls {model.repo_snapshot_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146c9ad-f99a-4030-bfa4-0bdaabfc2144",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "Log the Huggingface pipeline to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0908b-d906-4ed2-ad0e-2dcc9588012c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family: Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.5; color: #333; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 4px; padding: 15px; margin-bottom: 15px;\">\n",
       "        <h3 style=\"margin-top: 0; margin-bottom: 10px; font-size: 16px; color: #007bff;\">\n",
       "            Model Version Details\n",
       "        </h3>\n",
       "        \n",
       "    <div style=\"display: grid; grid-template-columns: 150px 1fr; gap: 10px;\">\n",
       "        \n",
       "            <div style=\"font-weight: bold;\">Model Name:</div>\n",
       "            <div>MED_GEMMA_4B</div>\n",
       "        \n",
       "            <div style=\"font-weight: bold;\">Version:</div>\n",
       "            <div><strong style=\"color: #28a745;\">EMPTY_RABBIT_4</strong></div>\n",
       "        \n",
       "            <div style=\"font-weight: bold;\">Full Name:</div>\n",
       "            <div>PAVI_DEMO.PUBLIC.MED_GEMMA_4B</div>\n",
       "        \n",
       "            <div style=\"font-weight: bold;\">Description:</div>\n",
       "            <div>None</div>\n",
       "        \n",
       "            <div style=\"font-weight: bold;\">Task:</div>\n",
       "            <div>UNKNOWN</div>\n",
       "        \n",
       "    </div>\n",
       "    <h4 style=\"margin: 15px 0 10px; color: #007bff;\">Functions</h4>\n",
       "    <div style=\"margin-left: 10px;\">\n",
       "        \n",
       "    <details style=\"margin: 5px 0; border: 1px solid #e0e0e0; border-radius: 4px;\" >\n",
       "        <summary style=\"padding: 8px; cursor: pointer; background-color: #f5f5f5; border-radius: 3px;\">\n",
       "            <span style=\"font-weight: bold; color: #007bff;\">__CALL__</span>\n",
       "        </summary>\n",
       "        <div style=\"padding: 10px; border-top: 1px solid #e0e0e0;\">\n",
       "            \n",
       "                        <div style=\"margin: 5px 0;\">\n",
       "                            <strong>Target Method:</strong> __call__\n",
       "                        </div>\n",
       "                        <div style=\"margin: 5px 0;\">\n",
       "                            <strong>Function Type:</strong> FUNCTION\n",
       "                        </div>\n",
       "                        <div style=\"margin: 5px 0;\">\n",
       "                            <strong>Partitioned:</strong> False\n",
       "                        </div>\n",
       "                        <div style=\"margin: 10px 0;\">\n",
       "                            <strong>Signature:</strong>\n",
       "                            \n",
       "    <div style=\"font-family: Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.5; color: #333; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 4px; padding: 15px; margin-bottom: 15px;\">\n",
       "        <h3 style=\"margin-top: 0; margin-bottom: 10px; font-size: 16px; color: #007bff;\">\n",
       "            Model Signature\n",
       "        </h3>\n",
       "        \n",
       "        <div style=\"margin-top: 10px;\">\n",
       "            \n",
       "    <details style=\"margin: 5px 0; border: 1px solid #e0e0e0; border-radius: 4px;\" open>\n",
       "        <summary style=\"padding: 8px; cursor: pointer; background-color: #f5f5f5; border-radius: 3px;\">\n",
       "            <span style=\"font-weight: bold; color: #007bff;\">Inputs</span>\n",
       "        </summary>\n",
       "        <div style=\"padding: 10px; border-top: 1px solid #e0e0e0;\">\n",
       "            \n",
       "        <div style=\"margin: 5px 0; padding: 5px;\">\n",
       "    \n",
       "            <div style=\"margin: 8px 0;\">\n",
       "                <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                    <strong>messages</strong> <span style=\"color: #666;\">(group)</span>\n",
       "                </div>\n",
       "                <div style=\"border-left: 2px solid #e0e0e0; margin-left: 8px;\">\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>content</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>name</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>role</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>title</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>temperature</strong>: DataType.DOUBLE\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>max_completion_tokens</strong>: DataType.INT64\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>stop</strong>: DataType.STRING shape=(-1,)\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>n</strong>: DataType.INT32\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>stream</strong>: DataType.BOOL\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>top_p</strong>: DataType.DOUBLE\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>frequency_penalty</strong>: DataType.DOUBLE\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>presence_penalty</strong>: DataType.DOUBLE\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>\n",
       "    </details>\n",
       "    \n",
       "            \n",
       "    <details style=\"margin: 5px 0; border: 1px solid #e0e0e0; border-radius: 4px;\" open>\n",
       "        <summary style=\"padding: 8px; cursor: pointer; background-color: #f5f5f5; border-radius: 3px;\">\n",
       "            <span style=\"font-weight: bold; color: #007bff;\">Outputs</span>\n",
       "        </summary>\n",
       "        <div style=\"padding: 10px; border-top: 1px solid #e0e0e0;\">\n",
       "            \n",
       "        <div style=\"margin: 5px 0; padding: 5px;\">\n",
       "    \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>id</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>object</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>created</strong>: DataType.FLOAT\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                <strong>model</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 8px 0;\">\n",
       "                <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                    <strong>choices</strong> <span style=\"color: #666;\">(group)</span>\n",
       "                </div>\n",
       "                <div style=\"border-left: 2px solid #e0e0e0; margin-left: 8px;\">\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>index</strong>: DataType.INT32\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 8px 0;\">\n",
       "                <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                    <strong>message</strong> <span style=\"color: #666;\">(group)</span>\n",
       "                </div>\n",
       "                <div style=\"border-left: 2px solid #e0e0e0; margin-left: 24px;\">\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 32px;\">\n",
       "                <strong>content</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 32px;\">\n",
       "                <strong>name</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 32px;\">\n",
       "                <strong>role</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>logprobs</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>finish_reason</strong>: DataType.STRING\n",
       "            </div>\n",
       "        \n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 8px 0;\">\n",
       "                <div style=\"margin: 3px 0; padding-left: 0px;\">\n",
       "                    <strong>usage</strong> <span style=\"color: #666;\">(group)</span>\n",
       "                </div>\n",
       "                <div style=\"border-left: 2px solid #e0e0e0; margin-left: 8px;\">\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>completion_tokens</strong>: DataType.INT32\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>prompt_tokens</strong>: DataType.INT32\n",
       "            </div>\n",
       "        \n",
       "            <div style=\"margin: 3px 0; padding-left: 16px;\">\n",
       "                <strong>total_tokens</strong>: DataType.INT32\n",
       "            </div>\n",
       "        \n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>\n",
       "    </details>\n",
       "    \n",
       "        </div>\n",
       "        \n",
       "    </div>\n",
       "    \n",
       "                        </div>\n",
       "                    \n",
       "        </div>\n",
       "    </details>\n",
       "    \n",
       "    </div>\n",
       "    <h4 style=\"margin: 15px 0 10px; color: #007bff;\">Metrics</h4>\n",
       "    <div style=\"margin-left: 10px;\">\n",
       "        <em style=\"color: #888; font-style: italic;\">No metrics available</em>\n",
       "    </div>\n",
       "    \n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "ModelVersion(\n",
       "  name='MED_GEMMA_4B',\n",
       "  version='EMPTY_RABBIT_4',\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv = registry.log_model(\n",
    "    model=model,\n",
    "    model_name=\"med_gemma_4b\",\n",
    "    # provides OpenAI Chat Completions compatible signature (input output format) to interact with the transformers model\n",
    "    signatures=openai_signatures.OPENAI_CHAT_SIGNATURE,\n",
    ")\n",
    "mv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a82eb-c8da-40cc-a32e-ee33e3242e4d",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "Create a service using the logged model. This usually takes few minutes and depends on the node availability in your compute pool.\n",
    "Once the service is up and running, the model can be inferred using SQL, Python API and REST Endpoints (if ingress is enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6dea2-404d-484c-9992-8f6b7460224d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "service_name = \"med_gemma_service\"\n",
    "\n",
    "mv.create_service(\n",
    "    service_name=\"med_gemma_service\",\n",
    "    service_compute_pool=\"<service_compute_pool>\",\n",
    "    gpu_requests=\"1\",\n",
    "    # if rest endpoint is required\n",
    "    ingress_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9563f-1573-438f-81b0-e3665da40ac2",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/snowml/lib/python3.10/site-packages/snowflake/ml/model/model_signature.py:671: UserWarning: Null value detected in column stop, model signature inference might not accurate, or your prediction might fail if your model does not support null input. If this is not expected, please check your input dataframe.\n",
      "  handler.validate(data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-43a83d69ada04062b709bfeabba377c1</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1758827776.0</td>\n",
       "      <td>/shared/model/model/models/MED_GEMMA_4B/model</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>{'completion_tokens': 750, 'prompt_tokens': 27...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id           object       created  \\\n",
       "0  chatcmpl-43a83d69ada04062b709bfeabba377c1  chat.completion  1758827776.0   \n",
       "\n",
       "                                           model  \\\n",
       "0  /shared/model/model/models/MED_GEMMA_4B/model   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
       "\n",
       "                                               usage  \n",
       "0  {'completion_tokens': 750, 'prompt_tokens': 27...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How do you differentiate bacterial from viral pneumonia?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# create a pd.DataFrame with openai.client.chat.completions arguments like below:\n",
    "x_df = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"max_completion_tokens\": 250,\n",
    "            \"temperature\": 0.9,\n",
    "            \"stop\": None,\n",
    "            \"n\": 3,\n",
    "            # Note streaming is not supported yet\n",
    "            \"stream\": False,\n",
    "            \"top_p\": 1.0,\n",
    "            \"frequency_penalty\": 0.1,\n",
    "            \"presence_penalty\": 0.2,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# To get the model version object\n",
    "# mv = registry.get_model(\"<model_name>\").version(\"<version_name>\"\")\n",
    "# OpenAI Chat Completion compatible output\n",
    "output_df = mv.run(X=x_df, service_name=service_name)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc57679-4e6f-40b9-bb3e-34c228870cab",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help you understand how a medical assistant can differentiate between bacterial and viral pneumonia.\n",
      "\n",
      "**How a Medical Assistant can help differentiate between bacterial and viral pneumonia:**\n",
      "\n",
      "**1. Medical History and Symptoms:**\n",
      "\n",
      "*   **Onset:**\n",
      "    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\n",
      "    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\n",
      "*   **Onset:**\n",
      "    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\n",
      "    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\n",
      "*   **Symptoms:**\n",
      "    *   **Bacterial pneumonia:**\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   \n"
     ]
    }
   ],
   "source": [
    "# Print the first choice\n",
    "print(output_df[\"choices\"][0][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57891793-3e6e-4f6d-b9f4-7fc0a60d1dda",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "! pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dcb94dd-4959-46da-a590-02c97f8de9c4",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I can help you understand how a medical assistant can differentiate between bacterial and viral pneumonia.\\n\\n**How a Medical Assistant can help differentiate between bacterial and viral pneumonia:**\\n\\n**1. Medical History and Symptoms:**\\n\\n*   **Onset:**\\n    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\\n    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\\n*   **Onset:**\\n    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\\n    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\\n*   **Symptoms:**\\n    *   **Bacterial pneumonia:**\\n        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\\n        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\\n        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\\n        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\\n        *   '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: To get OpenAI chat completion object\n",
    "# Note: requires openai python SDK `pip install openai`\n",
    "import openai\n",
    "\n",
    "\n",
    "def convert_to_openai_completion(df):\n",
    "    completions = []\n",
    "    for _, row in df.iterrows():\n",
    "        completions.append(openai.types.chat.ChatCompletion(**row))\n",
    "\n",
    "    return completions\n",
    "\n",
    "\n",
    "completions = convert_to_openai_completion(output_df)\n",
    "\n",
    "completions[0].choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d81189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bdk7a2g-sfengineering-mlplatformtest.awsuswest2preprod8.pp-snowflakecomputing.app'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingress_url = session.sql(f\"SHOW ENDPOINTS IN SERVICE {service_name}\").collect()[0][\n",
    "    \"ingress_url\"\n",
    "]\n",
    "ingress_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d89df",
   "metadata": {},
   "source": [
    "## To consume REST endpoint\n",
    "\n",
    "Consume the model inference using REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc47d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.utils import connection_params\n",
    "\n",
    "conn_cfg = connection_params.SnowflakeLoginOptions(\n",
    "    connection_name=\"...\",  # Optional\n",
    ")\n",
    "\n",
    "pat_token = conn_cfg.get(\"password\")\n",
    "headers = {\n",
    "    \"Authorization\": f'Snowflake Token=\"{pat_token}\"',\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a2cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URL = f\"https://{ingress_url}/--call--\"\n",
    "\n",
    "\n",
    "def invoke_endpoint(chat_requests, headers):\n",
    "    data_array = []\n",
    "    for i, chat_request in enumerate(chat_requests):\n",
    "        question_row = [i, chat_request]\n",
    "        data_array.append(question_row)\n",
    "\n",
    "    payload = {\"data\": data_array}\n",
    "\n",
    "    return requests.post(URL, headers=headers, json=payload)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How do you differentiate bacterial from viral pneumonia?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "chat_requests = [\n",
    "    {\n",
    "        \"messages\": messages,\n",
    "        \"max_completion_tokens\": 250,\n",
    "        \"temperature\": 0.9,\n",
    "        \"stop\": None,\n",
    "        \"n\": 3,\n",
    "        # Note streaming is not supported yet\n",
    "        \"stream\": False,\n",
    "        \"top_p\": 1.0,\n",
    "        \"frequency_penalty\": 0.1,\n",
    "        \"presence_penalty\": 0.2,\n",
    "    }\n",
    "]\n",
    "\n",
    "response = invoke_endpoint(chat_requests, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b292ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help you understand how a medical assistant can differentiate between bacterial and viral pneumonia.\n",
      "\n",
      "**How a Medical Assistant can help differentiate between bacterial and viral pneumonia:**\n",
      "\n",
      "**1. Medical History and Symptoms:**\n",
      "\n",
      "*   **Onset:**\n",
      "    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\n",
      "    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\n",
      "*   **Onset:**\n",
      "    *   **Bacterial pneumonia:** Often has a more sudden onset, can be more sudden and severe.\n",
      "    *   **Viral pneumonia:** Often has a more gradual onset, can be more gradual and more gradual.\n",
      "*   **Symptoms:**\n",
      "    *   **Bacterial pneumonia:**\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   **Symptoms:** Often has a more sudden onset, can be more sudden and severe.\n",
      "        *   \n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def convert_responses_to_openai_completion(responses):\n",
    "    completions = []\n",
    "    data = responses[\"data\"]\n",
    "    for item in data:\n",
    "        response = item[-1]\n",
    "        completions.append(openai.types.chat.ChatCompletion(**response))\n",
    "\n",
    "    return completions\n",
    "\n",
    "\n",
    "openai_completions = convert_responses_to_openai_completion(response.json())\n",
    "print(openai_completions[0].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa936c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "lastEditStatus": {
   "authorEmail": "p.ramachandran@snowflake.com",
   "authorId": "1900264113741",
   "authorName": "PRAMACHANDRAN",
   "lastEditTime": 1758825796536,
   "notebookId": "wcliz4mgunu2knzfdyet",
   "sessionId": "8ed1ec23-7aed-4eca-93c5-5221f6e50f0c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
