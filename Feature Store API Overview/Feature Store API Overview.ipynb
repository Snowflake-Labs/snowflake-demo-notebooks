{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last updated on: 8/6/2024\n",
    "- Required snowflake-ml-python version: >=**1.6.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Store API Overview\n",
    "\n",
    "This notebook provides an overview of Feature Store APIs. It demonstrates how to manage Feature Store, Feature Views, Feature Entities and how to retrieve features and generate training datasets etc. The goal is to provide a quick walkthrough of the most common APIs. For a full list of APIs, please refer to [API Reference page](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/feature_store).\n",
    "\n",
    "\n",
    "Note: there may be a delay in the availability of the newest snowflake-ml-python package in the Snowflake Conda channel. To install the latest snowflake-ml-python package which includes all of necessary components used in this notebook, please follow the install instructions [here](https://docs.snowflake.com/LIMITEDACCESS/snowpark-ml-library-update)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**:\n",
    "- [Set up connection and test dataset](#setup-test-environment)\n",
    "- [Manage features in Feature Store](#manage-features-in-feature-store)\n",
    "  - [Initialize a Feature Store](#initialize-a-feature-store)\n",
    "  - [Create entities](#create-entities)\n",
    "  - [Create feature views](#create-feature-views)\n",
    "  - [Add feature view versions](#add-feature-view-versions)\n",
    "  - [Update feature views](#update-feature-views)\n",
    "  - [Operate feature views](#operate-feature-views)\n",
    "  - [Retrieve values from a feature view](#read-values-from-a-feature-view)\n",
    "  - [Generate training data](#generate-training-data)\n",
    "  - [Delete feature views](#delete-feature-views)\n",
    "  - [Delete entities](#delete-entities)\n",
    "  - [Cleanup Feature Store](#cleanup-feature-store)\n",
    "- [Clean up notebook](#cleanup-notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup-test-environment'></a>\n",
    "## Set up connection and test dataset\n",
    "\n",
    "Let's start with setting up out test environment. We will create a session and a schema. The schema `FS_DEMO_SCHEMA` will be used as the Feature Store. It will be cleaned up at the end of the demo. You need to fill the `connection_parameters` with your Snowflake connection information. Follow this **[guide](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-session)** for more details about how to connect to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session, context, exceptions\n",
    "\n",
    "try:\n",
    "    # Retrieve active session if in Snowpark Notebook\n",
    "    session = context.get_active_session()\n",
    "except exceptions.SnowparkSessionException:\n",
    "    # ACTION REQUIRED: Need to manually configure Snowflake connection if using Jupyter\n",
    "    connection_parameters = {\n",
    "        \"account\": \"<your snowflake account>\",\n",
    "        \"user\": \"<your snowflake user>\",\n",
    "        \"password\": \"<your snowflake password>\",\n",
    "        \"role\": \"<your snowflake role>\",\n",
    "        \"warehouse\": \"<your snowflake warehouse>\",\n",
    "        \"database\": \"<your snowflake database>\",\n",
    "        \"schema\": \"<your snowflake schema>\",\n",
    "    }\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "assert session.get_current_database() != None, \"Session must have a database for the demo.\"\n",
    "assert session.get_current_warehouse() != None, \"Session must have a warehouse for the demo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Schema SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully created.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The schema where Feature Store will be initialized and test datasets stored.\n",
    "FS_DEMO_SCHEMA = \"SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO\"\n",
    "\n",
    "# Make sure your role has CREATE SCHEMA privileges or USAGE privileges on the schema if it already exists.\n",
    "session.sql(f\"CREATE OR REPLACE SCHEMA {FS_DEMO_SCHEMA}\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared some examples which you can find in our [open source repo](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). Each example contains the source dataset, feature view and entity definitions which will be used in this demo. `ExampleHelper` (included in snowflake-ml-python) will setup everything with simple APIs and you don't have to worry about the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>LABEL_COLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_york_taxi_features</td>\n",
       "      <td>Features using taxi trip data trying to predic...</td>\n",
       "      <td>TOTAL_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_features</td>\n",
       "      <td>Features using synthetic airline data to predi...</td>\n",
       "      <td>DEPARTING_DELAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine_quality_features</td>\n",
       "      <td>Features using wine quality data trying to pre...</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>citibike_trip_features</td>\n",
       "      <td>Features using citibike trip data trying to pr...</td>\n",
       "      <td>tripduration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NAME                                               DESC  \\\n",
       "0  new_york_taxi_features  Features using taxi trip data trying to predic...   \n",
       "1        airline_features  Features using synthetic airline data to predi...   \n",
       "2   wine_quality_features  Features using wine quality data trying to pre...   \n",
       "3  citibike_trip_features  Features using citibike trip data trying to pr...   \n",
       "\n",
       "        LABEL_COLS  \n",
       "0     TOTAL_AMOUNT  \n",
       "1  DEPARTING_DELAY  \n",
       "2          quality  \n",
       "3     tripduration  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.ml.feature_store.examples.example_helper import ExampleHelper\n",
    "\n",
    "example_helper = ExampleHelper(session, session.get_current_database(), FS_DEMO_SCHEMA)\n",
    "example_helper.list_examples().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly look at the newly generated source tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"REGTEST_DB\".SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO.citibike_trips:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TRIPDURATION</th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>STOPTIME</th>\n",
       "      <th>START_STATION_ID</th>\n",
       "      <th>START_STATION_NAME</th>\n",
       "      <th>START_STATION_LATITUDE</th>\n",
       "      <th>START_STATION_LONGITUDE</th>\n",
       "      <th>END_STATION_ID</th>\n",
       "      <th>END_STATION_NAME</th>\n",
       "      <th>END_STATION_LATITUDE</th>\n",
       "      <th>END_STATION_LONGITUDE</th>\n",
       "      <th>BIKEID</th>\n",
       "      <th>MEMBERSHIP_TYPE</th>\n",
       "      <th>USERTYPE</th>\n",
       "      <th>BIRTH_YEAR</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>2013-12-05 13:09:50</td>\n",
       "      <td>2013-12-05 13:15:17</td>\n",
       "      <td>523</td>\n",
       "      <td>W 38 St &amp; 8 Ave</td>\n",
       "      <td>40.754666</td>\n",
       "      <td>-73.991382</td>\n",
       "      <td>505</td>\n",
       "      <td>6 Ave &amp; W 33 St</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>15852</td>\n",
       "      <td>None</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "      <td>2013-12-05 13:09:52</td>\n",
       "      <td>2013-12-05 13:17:50</td>\n",
       "      <td>473</td>\n",
       "      <td>Rivington St &amp; Chrystie St</td>\n",
       "      <td>40.721101</td>\n",
       "      <td>-73.991925</td>\n",
       "      <td>161</td>\n",
       "      <td>LaGuardia Pl &amp; W 3 St</td>\n",
       "      <td>40.729170</td>\n",
       "      <td>-73.998102</td>\n",
       "      <td>17952</td>\n",
       "      <td>None</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>288</td>\n",
       "      <td>2013-12-05 13:09:54</td>\n",
       "      <td>2013-12-05 13:14:42</td>\n",
       "      <td>167</td>\n",
       "      <td>E 39 St &amp; 3 Ave</td>\n",
       "      <td>40.748901</td>\n",
       "      <td>-73.976049</td>\n",
       "      <td>524</td>\n",
       "      <td>W 43 St &amp; 6 Ave</td>\n",
       "      <td>40.755273</td>\n",
       "      <td>-73.983169</td>\n",
       "      <td>19033</td>\n",
       "      <td>None</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1163</td>\n",
       "      <td>2013-12-05 13:10:00</td>\n",
       "      <td>2013-12-05 13:29:23</td>\n",
       "      <td>229</td>\n",
       "      <td>Great Jones St</td>\n",
       "      <td>40.727434</td>\n",
       "      <td>-73.993790</td>\n",
       "      <td>347</td>\n",
       "      <td>W Houston St &amp; Hudson St</td>\n",
       "      <td>40.728739</td>\n",
       "      <td>-74.007488</td>\n",
       "      <td>17488</td>\n",
       "      <td>None</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>247</td>\n",
       "      <td>2013-12-05 13:10:04</td>\n",
       "      <td>2013-12-05 13:14:11</td>\n",
       "      <td>505</td>\n",
       "      <td>6 Ave &amp; W 33 St</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>466</td>\n",
       "      <td>W 25 St &amp; 6 Ave</td>\n",
       "      <td>40.743954</td>\n",
       "      <td>-73.991449</td>\n",
       "      <td>15838</td>\n",
       "      <td>None</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID  TRIPDURATION           STARTTIME            STOPTIME  \\\n",
       "0        1           327 2013-12-05 13:09:50 2013-12-05 13:15:17   \n",
       "1        2           478 2013-12-05 13:09:52 2013-12-05 13:17:50   \n",
       "2        3           288 2013-12-05 13:09:54 2013-12-05 13:14:42   \n",
       "3        4          1163 2013-12-05 13:10:00 2013-12-05 13:29:23   \n",
       "4        5           247 2013-12-05 13:10:04 2013-12-05 13:14:11   \n",
       "\n",
       "   START_STATION_ID          START_STATION_NAME  START_STATION_LATITUDE  \\\n",
       "0               523             W 38 St & 8 Ave               40.754666   \n",
       "1               473  Rivington St & Chrystie St               40.721101   \n",
       "2               167             E 39 St & 3 Ave               40.748901   \n",
       "3               229              Great Jones St               40.727434   \n",
       "4               505             6 Ave & W 33 St               40.749013   \n",
       "\n",
       "   START_STATION_LONGITUDE  END_STATION_ID          END_STATION_NAME  \\\n",
       "0               -73.991382             505           6 Ave & W 33 St   \n",
       "1               -73.991925             161     LaGuardia Pl & W 3 St   \n",
       "2               -73.976049             524           W 43 St & 6 Ave   \n",
       "3               -73.993790             347  W Houston St & Hudson St   \n",
       "4               -73.988484             466           W 25 St & 6 Ave   \n",
       "\n",
       "   END_STATION_LATITUDE  END_STATION_LONGITUDE  BIKEID MEMBERSHIP_TYPE  \\\n",
       "0             40.749013             -73.988484   15852            None   \n",
       "1             40.729170             -73.998102   17952            None   \n",
       "2             40.755273             -73.983169   19033            None   \n",
       "3             40.728739             -74.007488   17488            None   \n",
       "4             40.743954             -73.991449   15838            None   \n",
       "\n",
       "     USERTYPE  BIRTH_YEAR  GENDER  \n",
       "0  Subscriber        1980       1  \n",
       "1  Subscriber        1983       2  \n",
       "2  Subscriber        1988       1  \n",
       "3  Subscriber        1988       1  \n",
       "4  Subscriber        1965       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace the value with the example you want to run\n",
    "source_tables = example_helper.load_example('citibike_trip_features')\n",
    "# display as Pandas DataFrame\n",
    "for table in source_tables:\n",
    "    print(f\"{table}:\")\n",
    "    df = session.table(table).limit(5).to_pandas()\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='manage-features-in-feature-store'></a>\n",
    "## Manage features in Feature Store\n",
    "\n",
    "Now we're ready to create a  Feature Store. The sections below showcase how to create a Feature Store, entities, feature views and how to work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='initialize-a-feature-store'></a>\n",
    "### Initialize a Feature Store\n",
    "\n",
    "Firstly, we create a new (or connect to an existing) Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode,\n",
    "    FeatureViewStatus,\n",
    ")\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=session.get_current_database(), \n",
    "    name=FS_DEMO_SCHEMA, \n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create-entities'></a>\n",
    "### Create entities\n",
    "\n",
    "Before we can create  feature views, we need to create entities. The cell below registers the entities that are pre-defined for this example, and loaded by `helper.load_entities()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "|\"NAME\"          |\"JOIN_KEYS\"         |\"DESC\"                     |\"OWNER\"     |\n",
      "--------------------------------------------------------------------------------\n",
      "|END_STATION_ID  |[\"END_STATION_ID\"]  |The id of an end station.  |REGTEST_RL  |\n",
      "|TRIP_ID         |[\"TRIP_ID\"]         |The id of a trip.          |REGTEST_RL  |\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in example_helper.load_entities():\n",
    "    fs.register_entity(e)\n",
    "all_entities_df = fs.list_entities()\n",
    "all_entities_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get registered entities by name from Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running with other examples besides citibike_trip_features, replace with other entity name.\n",
    "entity_name = 'end_station_id'\n",
    "my_entity = fs.get_entity(entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create-feature-views'></a>\n",
    "### Create feature views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can register feature views. Feature views also are pre-defined in our repository. You can find the definitions [here](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"NAME\"     |\"VERSION\"  |\"DESC\"                                 |\"REFRESH_FREQ\"  |\n",
      "----------------------------------------------------------------------------------\n",
      "|F_STATION  |1.0        |Station features refreshed every day.  |1 day           |\n",
      "|F_TRIP     |1.0        |Static trip features                   |NULL            |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fv in example_helper.load_draft_feature_views():\n",
    "    fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='1.0'\n",
    "    )\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq')\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can specify feature view versions and attach descriptive comments in the “DESC” field to make search and discovery of features easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='add-feature-view-versions'></a>\n",
    "### Add feature view versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add new versions in a feature view by using the same name as an existing feature view but a different version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/c3pzglr908q2p0w5w9vzhy0m0000gn/T/ipykernel_22612/1306387384.py:2: UserWarning: You must call register_feature_view() to make it effective. Or use update_feature_view(desc=<new_value>).\n",
      "  fv.desc = f'{fv.name}/2.0 with new desc.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"NAME\"     |\"VERSION\"  |\"DESC\"                                 |\"REFRESH_FREQ\"  |\n",
      "----------------------------------------------------------------------------------\n",
      "|F_STATION  |1.0        |Station features refreshed every day.  |1 day           |\n",
      "|F_STATION  |2.0        |F_STATION/2.0 with new desc.           |1 day           |\n",
      "|F_TRIP     |1.0        |Static trip features                   |NULL            |\n",
      "|F_TRIP     |2.0        |F_TRIP/2.0 with new desc.              |NULL            |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fv in example_helper.load_draft_feature_views():\n",
    "    fv.desc = f'{fv.name}/2.0 with new desc.'\n",
    "    fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='2.0'\n",
    "    )\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq')\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='update-feature-views'></a>\n",
    "### Update feature views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a feature view is registered, it is materialized to Snowflake backend. You can still update some metadata for a registered feature view with `update_feature_view`. Below cell updates the `desc` of a managed feature view. You can check our [API reference](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/api/feature_store/snowflake.ml.feature_store.FeatureStore) page to find the full list of metadata that can be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "|\"NAME\"     |\"VERSION\"  |\"DESC\"                        |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|F_STATION  |1.0        |Updated desc for f_station.   |1 day           |ACTIVE              |\n",
      "|F_STATION  |2.0        |F_STATION/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if you are running other examples besides citibike_trip_features, replace with other feature view name.\n",
    "target_feature_view = 'f_station'\n",
    "updated_fv = fs.update_feature_view(\n",
    "    name=target_feature_view,\n",
    "    version='1.0',\n",
    "    desc=f'Updated desc for {target_feature_view}.', \n",
    ")\n",
    "\n",
    "assert updated_fv.desc == f'Updated desc for {target_feature_view}.'\n",
    "fs.list_feature_views(feature_view_name=target_feature_view) \\\n",
    "    .select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='operate-feature-views'></a>\n",
    "### Operate feature views\n",
    "\n",
    "For **managed feature views**, you can suspend, resume, or manually refresh the backend pipelines. A managed feature view is an automated feature pipeline that computes the features on a given schedule. You create a managed feature view by setting the `refresh_freq`. In contrast, a **static feature view** is created when `refresh_freq` is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "|\"NAME\"     |\"VERSION\"  |\"DESC\"                        |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|F_STATION  |1.0        |Updated desc for f_station.   |1 day           |SUSPENDED           |\n",
      "|F_STATION  |2.0        |F_STATION/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "|F_TRIP     |1.0        |Static trip features          |NULL            |NULL                |\n",
      "|F_TRIP     |2.0        |F_TRIP/2.0 with new desc.     |NULL            |NULL                |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "registered_fv = fs.get_feature_view(target_feature_view, '1.0')\n",
    "suspended_fv = fs.suspend_feature_view(registered_fv)\n",
    "assert suspended_fv.status == FeatureViewStatus.SUSPENDED\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "|\"NAME\"     |\"VERSION\"  |\"DESC\"                        |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|F_STATION  |1.0        |Updated desc for f_station.   |1 day           |ACTIVE              |\n",
      "|F_STATION  |2.0        |F_STATION/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "|F_TRIP     |1.0        |Static trip features          |NULL            |NULL                |\n",
      "|F_TRIP     |2.0        |F_TRIP/2.0 with new desc.     |NULL            |NULL                |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resumed_fv = fs.resume_feature_view(suspended_fv)\n",
    "assert resumed_fv.status == FeatureViewStatus.ACTIVE\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"         |\"STATE\"    |\"REFRESH_START_TIME\"              |\"REFRESH_END_TIME\"                |\"REFRESH_ACTION\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:41:17.171000-07:00  |2024-08-06 09:41:17.547000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:42:56.835000-07:00  |2024-08-06 09:42:57.612000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:43:34.390000-07:00  |2024-08-06 09:43:34.884000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:44:10.294000-07:00  |2024-08-06 09:44:10.860000-07:00  |INCREMENTAL       |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_df_before = fs.get_refresh_history(resumed_fv).order_by('REFRESH_START_TIME')\n",
    "history_df_before.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below manually refreshes a feature view. It triggers the feature computation on the latest source data. You can check the refresh history with `get_refresh_history()` and you will see updated results from previous `get_refresh_history()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"         |\"STATE\"    |\"REFRESH_START_TIME\"              |\"REFRESH_END_TIME\"                |\"REFRESH_ACTION\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:41:17.171000-07:00  |2024-08-06 09:41:17.547000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:42:56.835000-07:00  |2024-08-06 09:42:57.612000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:43:34.390000-07:00  |2024-08-06 09:43:34.884000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:44:10.294000-07:00  |2024-08-06 09:44:10.860000-07:00  |INCREMENTAL       |\n",
      "|F_STATION$1.0  |SUCCEEDED  |2024-08-06 09:44:48.016000-07:00  |2024-08-06 09:44:48.449000-07:00  |INCREMENTAL       |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs.refresh_feature_view(resumed_fv)\n",
    "history_df_after = fs.get_refresh_history(resumed_fv).order_by('REFRESH_START_TIME')\n",
    "history_df_after.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read-values-from-a-feature-view'></a>\n",
    "### Retrieve values from a feature view "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the feature value of a registered feature view with `read_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "|\"END_STATION_ID\"  |\"F_COUNT\"  |\"F_AVG_LATITUDE\"  |\"F_AVG_LONGTITUDE\"  |\n",
      "------------------------------------------------------------------------\n",
      "|505               |483        |40.74901271       |-73.98848395        |\n",
      "|161               |429        |40.72917025       |-73.99810231        |\n",
      "|347               |440        |40.72873888       |-74.00748842        |\n",
      "|466               |425        |40.74395411       |-73.99144871        |\n",
      "|459               |456        |40.746745         |-74.007756          |\n",
      "|247               |241        |40.73535398       |-74.00483090999998  |\n",
      "|127               |481        |40.73172428       |-74.00674436        |\n",
      "|2000              |121        |40.70255088       |-73.98940236        |\n",
      "|514               |272        |40.76087502       |-74.00277668        |\n",
      "|195               |219        |40.70905623       |-74.01043382        |\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_value_df = fs.read_feature_view(resumed_fv)\n",
    "feature_value_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generate-training-data'></a>\n",
    "### Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate training data easily from Feature Store and output it either as a [Dataset object](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset), or as Snowpark DataFrame.\n",
    "The cell below creates a spine dataframe by randomly sampling some entity keys from source table. generate_dataset() then creates a Dataset object by populating the spine_df with respective feature values from selected feature views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_key_names = ','.join(my_entity.join_keys)\n",
    "spine_df = session.sql(f\"select {entity_key_names} from {source_tables[0]}\").sample(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use generate_dataset() to output a Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fv = fs.get_feature_view(target_feature_view, '1.0')\n",
    "\n",
    "my_dataset = fs.generate_dataset(\n",
    "    name='my_cool_dataset',\n",
    "    version='first',\n",
    "    spine_df=spine_df,\n",
    "    features=[training_fv],\n",
    "    desc='This is my dataset joined with feature views',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset to Pandas DataFrame and look at the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>END_STATION_ID</th>\n",
       "      <th>F_COUNT</th>\n",
       "      <th>F_AVG_LATITUDE</th>\n",
       "      <th>F_AVG_LONGTITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253</td>\n",
       "      <td>391</td>\n",
       "      <td>40.735439</td>\n",
       "      <td>-73.994537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368</td>\n",
       "      <td>486</td>\n",
       "      <td>40.730385</td>\n",
       "      <td>-74.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "      <td>451</td>\n",
       "      <td>40.736492</td>\n",
       "      <td>-73.997047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>477</td>\n",
       "      <td>759</td>\n",
       "      <td>40.756405</td>\n",
       "      <td>-73.990028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>147</td>\n",
       "      <td>40.690891</td>\n",
       "      <td>-73.996124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>521</td>\n",
       "      <td>956</td>\n",
       "      <td>40.750450</td>\n",
       "      <td>-73.994812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>375</td>\n",
       "      <td>497</td>\n",
       "      <td>40.726795</td>\n",
       "      <td>-73.996948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>350</td>\n",
       "      <td>258</td>\n",
       "      <td>40.715595</td>\n",
       "      <td>-73.987030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>337</td>\n",
       "      <td>112</td>\n",
       "      <td>40.703800</td>\n",
       "      <td>-74.008385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>497</td>\n",
       "      <td>911</td>\n",
       "      <td>40.737049</td>\n",
       "      <td>-73.990089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   END_STATION_ID  F_COUNT  F_AVG_LATITUDE  F_AVG_LONGTITUDE\n",
       "0             253      391       40.735439        -73.994537\n",
       "1             368      486       40.730385        -74.002151\n",
       "2             345      451       40.736492        -73.997047\n",
       "3             477      759       40.756405        -73.990028\n",
       "4             157      147       40.690891        -73.996124\n",
       "5             521      956       40.750450        -73.994812\n",
       "6             375      497       40.726795        -73.996948\n",
       "7             350      258       40.715595        -73.987030\n",
       "8             337      112       40.703800        -74.008385\n",
       "9             497      911       40.737049        -73.990089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.read.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset object materializes data in Parquet files on internal stages. Alternatively, you can use  `generate_training_set()` to output training data as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "|\"END_STATION_ID\"  |\"F_COUNT\"  |\"F_AVG_LATITUDE\"  |\"F_AVG_LONGTITUDE\"  |\n",
      "------------------------------------------------------------------------\n",
      "|195               |219        |40.70905623       |-74.01043382        |\n",
      "|398               |69         |40.69165183       |-73.9999786         |\n",
      "|329               |361        |40.72043411       |-74.01020609        |\n",
      "|498               |368        |40.74854862       |-73.98808416        |\n",
      "|319               |252        |40.71336124       |-74.00937622        |\n",
      "|369               |265        |40.73224119       |-74.00026394        |\n",
      "|459               |456        |40.746745         |-74.007756          |\n",
      "|311               |228        |40.7172274        |-73.98802084        |\n",
      "|480               |242        |40.76669671       |-73.99061728        |\n",
      "|127               |481        |40.73172428       |-74.00674436        |\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_df = fs.generate_training_set(\n",
    "    spine_df=spine_df,\n",
    "    features=[training_fv]\n",
    ")\n",
    "\n",
    "training_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='delete-feature-views'></a>\n",
    "### Delete feature views\n",
    "\n",
    "Feature views can be deleted via `delete_feature_view()`.\n",
    "\n",
    "Warning: Deleting a feature view may break downstream dependencies for other feature views or models that depend on the feature view being deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "|\"NAME\"  |\"VERSION\"  |\n",
      "----------------------\n",
      "|        |           |\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in fs.list_feature_views().collect():\n",
    "    fv = fs.get_feature_view(row['NAME'], row['VERSION'])\n",
    "    fs.delete_feature_view(fv)\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version') \n",
    "assert all_fvs_df.count() == 0, \"0 feature views left after deletion.\"\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='delete-entities'></a>\n",
    "### Delete entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete entity with `delete_entity()`. Note it will check whether there are feature views registered on this entity before it gets deleted, otherwise the deletion will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|\"NAME\"  |\"JOIN_KEYS\"  |\"DESC\"  |\"OWNER\"  |\n",
      "-------------------------------------------\n",
      "|        |             |        |         |\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in fs.list_entities().collect():\n",
    "    fs.delete_entity(row['NAME'])\n",
    "\n",
    "all_entities_df = fs.list_entities()\n",
    "assert all_entities_df.count() == 0, \"0 entities after deletion.\"\n",
    "all_entities_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanup-feature-store'></a>\n",
    "### Cleanup Feature Store (experimental) \n",
    "\n",
    "Currently we provide an experimental API to delete all entities and feature views in a Feature Store for easy cleanup. If \"dryrun\" is set to True (the default) then `fs._clear()` only prints the objects that will be deleted. If \"dryrun\" is set to False, it performs the deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/snowml/snowflake/ml/feature_store/feature_store.py:190: UserWarning: It will clear ALL feature views and entities in this Feature Store. Make sure your role has sufficient access to all feature views and entities. Insufficient access to some feature views or entities will leave Feature Store in an incomplete state.\n",
      "  return f(self, *args, **kargs)\n"
     ]
    }
   ],
   "source": [
    "fs._clear(dryrun=False)\n",
    "\n",
    "assert fs.list_feature_views().count() == 0, \"0 feature views left after deletion.\"\n",
    "assert fs.list_entities().count() == 0, \"0 entities left after deletion.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanup-notebook'></a>\n",
    "## Clean up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully dropped.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(f\"DROP SCHEMA IF EXISTS {FS_DEMO_SCHEMA}\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
