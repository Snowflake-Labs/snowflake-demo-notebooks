{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last updated on: 7/25/2024\n",
    "- Required snowflake-ml-python version: >=**1.6.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Store API Overview\n",
    "\n",
    "This notebook provides an overview of Feature Store APIs. It demonstrates how to manage Feature Store, Feature Views, Feature Entities and how to retrieve features and generate training datasets etc. The goal is to provide a quick walkthrough of the most common APIs. For a full list of APIs, please refer to [API Reference page](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/feature_store)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**:\n",
    "- [Set up connection and test dataset](#setup-test-environment)\n",
    "- [Manage features in Feature Store](#manage-features-in-feature-store)\n",
    "  - [Initialize a Feature Store](#initialize-a-feature-store)\n",
    "  - [Create entities](#create-entities)\n",
    "  - [Create feature views](#create-feature-views)\n",
    "  - [Add feature view versions](#add-feature-view-versions)\n",
    "  - [Update feature views](#update-feature-views)\n",
    "  - [Operate feature views](#operate-feature-views)\n",
    "  - [Retrieve values from a feature view](#read-values-from-a-feature-view)\n",
    "  - [Generate training data](#generate-training-data)\n",
    "  - [Delete feature views](#delete-feature-views)\n",
    "  - [Delete entities](#delete-entities)\n",
    "  - [Cleanup Feature Store](#cleanup-feature-store)\n",
    "- [Clean up notebook](#cleanup-notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup-test-environment'></a>\n",
    "## Set up connection and test dataset\n",
    "\n",
    "Let's start with setting up out test environment. We will create a session and a schema. The schema `FS_DEMO_SCHEMA` will be used as the Feature Store. It will be cleaned up at the end of the demo. You need to fill the `connection_parameters` with your Snowflake connection information. Follow this **[guide](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-session)** for more details about how to connect to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session, context, exceptions\n",
    "\n",
    "try:\n",
    "    # Retrieve active session if in Snowpark Notebook\n",
    "    session = context.get_active_session()\n",
    "except exceptions.SnowparkSessionException:\n",
    "    # ACTION REQUIRED: Need to manually configure Snowflake connection if using Jupyter\n",
    "    connection_parameters = {\n",
    "        \"account\": \"<your snowflake account>\",\n",
    "        \"user\": \"<your snowflake user>\",\n",
    "        \"password\": \"<your snowflake password>\",\n",
    "        \"role\": \"<your snowflake role>\",\n",
    "        \"warehouse\": \"<your snowflake warehouse>\",\n",
    "        \"database\": \"<your snowflake database>\",\n",
    "        \"schema\": \"<your snowflake schema>\",\n",
    "    }\n",
    "\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "assert session.get_current_database() != None, \"Session must have a database for the demo.\"\n",
    "assert session.get_current_warehouse() != None, \"Session must have a warehouse for the demo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Schema SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully created.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The schema where Feature Store will be initialized and test datasets stored.\n",
    "FS_DEMO_SCHEMA = \"SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO\"\n",
    "\n",
    "# Make sure your role has CREATE SCHEMA privileges or USAGE privileges on the schema if it already exists.\n",
    "session.sql(f\"CREATE OR REPLACE SCHEMA {FS_DEMO_SCHEMA}\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared some examples which you can find in our [open source repo](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). Each example contains the source dataset, feature view and entity definitions which will be used in this demo. `ExampleHelper` (included in snowflake-ml-python) will setup everything with simple APIs and you don't have to worry about the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All examples: ['new_york_taxi_features', 'citibike_trip_features', 'wine_quality_features']\n"
     ]
    }
   ],
   "source": [
    "from snowflake.ml.feature_store.examples.example_helper import ExampleHelper\n",
    "\n",
    "helper = ExampleHelper(session, session.get_current_database(), FS_DEMO_SCHEMA)\n",
    "print(f\"All examples: {helper.list_examples()}\")\n",
    "\n",
    "source_tables = helper.load_example('citibike_trip_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly look at the newly generated source tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display as Pandas dataframe\n",
    "for s in source_tables:\n",
    "    total_rows = session.table(s).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='manage-features-in-feature-store'></a>\n",
    "## Manage features in Feature Store\n",
    "\n",
    "Now we're ready to create a  Feature Store. The sections below showcase how to create a Feature Store, entities, feature views and how to work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='initialize-a-feature-store'></a>\n",
    "### Initialize a Feature Store\n",
    "\n",
    "Firstly, we create a new (or connect to an existing) Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode,\n",
    "    FeatureViewStatus,\n",
    ")\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=session.get_current_database(), \n",
    "    name=FS_DEMO_SCHEMA, \n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create-entities'></a>\n",
    "### Create entities\n",
    "\n",
    "Before we can create  feature views, we need to create entities. The cell below registers the entities that are pre-defined for this example, and loaded by `helper.load_entities()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "|\"NAME\"          |\"JOIN_KEYS\"         |\"DESC\"                     |\"OWNER\"     |\n",
      "--------------------------------------------------------------------------------\n",
      "|END_STATION_ID  |[\"END_STATION_ID\"]  |The id of an end station.  |REGTEST_RL  |\n",
      "|TRIP_ID         |[\"TRIP_ID\"]         |The id of a trip.          |REGTEST_RL  |\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in helper.load_entities():\n",
    "    fs.register_entity(e)\n",
    "all_entities_df = fs.list_entities()\n",
    "all_entities_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get registered entities by name from Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running with other examples besides citibike_trip_features, replace with other entity name.\n",
    "entity_name = 'end_station_id'\n",
    "my_entity = fs.get_entity(entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create-feature-views'></a>\n",
    "### Create feature views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can register feature views. Feature views also are pre-defined in our repository. You can find the definitions [here](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "|\"NAME\"        |\"VERSION\"  |\"DESC\"                                 |\"REFRESH_FREQ\"  |\n",
      "-------------------------------------------------------------------------------------\n",
      "|F_STATION_1D  |1.0        |Station features refreshed every day.  |1 day           |\n",
      "|F_TRIP        |1.0        |Static trip features                   |NULL            |\n",
      "-------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fv in helper.load_draft_feature_views():\n",
    "    fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='1.0'\n",
    "    )\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq')\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can specify feature view versions and attach descriptive comments in the “DESC” field to make search and discovery of features easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='add-feature-view-versions'></a>\n",
    "### Add feature view versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add new versions in a feature view by using the same name as an existing feature view but a different version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/c3pzglr908q2p0w5w9vzhy0m0000gn/T/ipykernel_78291/3965221163.py:2: UserWarning: You must call register_feature_view() to make it effective. Or use update_feature_view(desc=<new_value>).\n",
      "  fv.desc = f'{fv.name}/2.0 with new desc.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "|\"NAME\"        |\"VERSION\"  |\"DESC\"                                 |\"REFRESH_FREQ\"  |\n",
      "-------------------------------------------------------------------------------------\n",
      "|F_STATION_1D  |1.0        |Station features refreshed every day.  |1 day           |\n",
      "|F_STATION_1D  |2.0        |F_STATION_1D/2.0 with new desc.        |1 day           |\n",
      "|F_TRIP        |1.0        |Static trip features                   |NULL            |\n",
      "|F_TRIP        |2.0        |F_TRIP/2.0 with new desc.              |NULL            |\n",
      "-------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fv in helper.load_draft_feature_views():\n",
    "    fv.desc = f'{fv.name}/2.0 with new desc.'\n",
    "    fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='2.0'\n",
    "    )\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq')\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='update-feature-views'></a>\n",
    "### Update feature views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a feature view is registered, it is materialized to Snowflake backend. You can still update some metadata for a registered feature view with `update_feature_view`. Below cell updates the `desc` of a managed feature view. You can check our [API reference](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/api/feature_store/snowflake.ml.feature_store.FeatureStore) page to find the full list of metadata that can be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"        |\"VERSION\"  |\"DESC\"                           |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|F_STATION_1D  |1.0        |Updated desc for f_station_1d.   |1 day           |ACTIVE              |\n",
      "|F_STATION_1D  |2.0        |F_STATION_1D/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if you are running other examples besides citibike_trip_features, replace with other feature view name.\n",
    "target_feature_view = 'f_station_1d'\n",
    "updated_fv = fs.update_feature_view(\n",
    "    name=target_feature_view,\n",
    "    version='1.0',\n",
    "    desc=f'Updated desc for {target_feature_view}.', \n",
    ")\n",
    "\n",
    "assert updated_fv.desc == f'Updated desc for {target_feature_view}.'\n",
    "fs.list_feature_views(feature_view_name=target_feature_view) \\\n",
    "    .select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='operate-feature-views'></a>\n",
    "### Operate feature views\n",
    "\n",
    "For **managed feature views**, you can suspend, resume, or manually refresh the backend pipelines. A managed feature view is an automated feature pipeline that computes the features on a given schedule. You create a managed feature view by setting the `refresh_freq`. In contrast, a **static feature view** is created when `refresh_freq` is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"        |\"VERSION\"  |\"DESC\"                           |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|F_STATION_1D  |1.0        |Updated desc for f_station_1d.   |1 day           |SUSPENDED           |\n",
      "|F_STATION_1D  |2.0        |F_STATION_1D/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "|F_TRIP        |1.0        |Static trip features             |NULL            |NULL                |\n",
      "|F_TRIP        |2.0        |F_TRIP/2.0 with new desc.        |NULL            |NULL                |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "registered_fv = fs.get_feature_view(target_feature_view, '1.0')\n",
    "suspended_fv = fs.suspend_feature_view(registered_fv)\n",
    "assert suspended_fv.status == FeatureViewStatus.SUSPENDED\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"        |\"VERSION\"  |\"DESC\"                           |\"REFRESH_FREQ\"  |\"SCHEDULING_STATE\"  |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|F_STATION_1D  |1.0        |Updated desc for f_station_1d.   |1 day           |ACTIVE              |\n",
      "|F_STATION_1D  |2.0        |F_STATION_1D/2.0 with new desc.  |1 day           |ACTIVE              |\n",
      "|F_TRIP        |1.0        |Static trip features             |NULL            |NULL                |\n",
      "|F_TRIP        |2.0        |F_TRIP/2.0 with new desc.        |NULL            |NULL                |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resumed_fv = fs.resume_feature_view(suspended_fv)\n",
    "assert resumed_fv.status == FeatureViewStatus.ACTIVE\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq', 'scheduling_state').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"            |\"STATE\"    |\"REFRESH_START_TIME\"              |\"REFRESH_END_TIME\"                |\"REFRESH_ACTION\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:51:22.421000-07:00  |2024-07-19 11:51:23.089000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:51:56.100000-07:00  |2024-07-19 11:51:56.474000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:52:58.376000-07:00  |2024-07-19 11:52:58.943000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:53:33.424000-07:00  |2024-07-19 11:53:33.777000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:54:30.754000-07:00  |2024-07-19 11:54:31.446000-07:00  |INCREMENTAL       |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_df_before = fs.get_refresh_history(resumed_fv).order_by('REFRESH_START_TIME')\n",
    "history_df_before.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below manually refreshes a feature view. It triggers the feature computation on the latest source data. You can check the refresh history with `get_refresh_history()` and you will see updated results from previous `get_refresh_history()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"            |\"STATE\"    |\"REFRESH_START_TIME\"              |\"REFRESH_END_TIME\"                |\"REFRESH_ACTION\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:51:22.421000-07:00  |2024-07-19 11:51:23.089000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:51:56.100000-07:00  |2024-07-19 11:51:56.474000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:52:58.376000-07:00  |2024-07-19 11:52:58.943000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:53:33.424000-07:00  |2024-07-19 11:53:33.777000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:54:30.754000-07:00  |2024-07-19 11:54:31.446000-07:00  |INCREMENTAL       |\n",
      "|F_STATION_1D$1.0  |SUCCEEDED  |2024-07-19 11:55:04.462000-07:00  |2024-07-19 11:55:04.830000-07:00  |INCREMENTAL       |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs.refresh_feature_view(resumed_fv)\n",
    "history_df_after = fs.get_refresh_history(resumed_fv).order_by('REFRESH_START_TIME')\n",
    "history_df_after.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read-values-from-a-feature-view'></a>\n",
    "### Retrieve values from a feature view "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the feature value of a registered feature view with `read_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "|\"END_STATION_ID\"  |\"F_COUNT_1D\"  |\"F_AVG_LATITUDE_1D\"  |\"F_AVG_LONGTITUDE_1D\"  |\n",
      "---------------------------------------------------------------------------------\n",
      "|505               |483           |40.74901271          |-73.98848395           |\n",
      "|161               |429           |40.72917025          |-73.99810231           |\n",
      "|347               |440           |40.72873888          |-74.00748842           |\n",
      "|466               |425           |40.74395411          |-73.99144871           |\n",
      "|459               |456           |40.746745            |-74.007756             |\n",
      "|247               |241           |40.73535398          |-74.00483090999998     |\n",
      "|127               |481           |40.73172428          |-74.00674436           |\n",
      "|2000              |121           |40.70255088          |-73.98940236           |\n",
      "|514               |272           |40.76087502          |-74.00277668           |\n",
      "|195               |219           |40.70905623          |-74.01043382           |\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_value_df = fs.read_feature_view(resumed_fv)\n",
    "feature_value_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generate-training-data'></a>\n",
    "### Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate training data easily from Feature Store and output it either as a [Dataset object](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset), or as Snowpark DataFrame.\n",
    "The cell below creates a spine dataframe by randomly sampling some entity keys from source table. generate_dataset() then creates a Dataset object by populating the spine_df with respective feature values from selected feature views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_key_names = ','.join(my_entity.join_keys)\n",
    "spine_df = session.sql(f\"select {entity_key_names} from {source_tables[0]}\").sample(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use generate_dataset() to output a Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fv = fs.get_feature_view(target_feature_view, '1.0')\n",
    "\n",
    "my_dataset = fs.generate_dataset(\n",
    "    name='my_cool_dataset',\n",
    "    version='first',\n",
    "    spine_df=spine_df,\n",
    "    features=[training_fv],\n",
    "    desc='This is my dataset joined with feature views',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset to Pandas DataFrame and look at the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>END_STATION_ID</th>\n",
       "      <th>F_COUNT_1D</th>\n",
       "      <th>F_AVG_LATITUDE_1D</th>\n",
       "      <th>F_AVG_LONGTITUDE_1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>441</td>\n",
       "      <td>187</td>\n",
       "      <td>40.756016</td>\n",
       "      <td>-73.967415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295</td>\n",
       "      <td>203</td>\n",
       "      <td>40.714066</td>\n",
       "      <td>-73.992943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>486</td>\n",
       "      <td>323</td>\n",
       "      <td>40.746201</td>\n",
       "      <td>-73.988556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308</td>\n",
       "      <td>187</td>\n",
       "      <td>40.713078</td>\n",
       "      <td>-73.998512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284</td>\n",
       "      <td>688</td>\n",
       "      <td>40.739017</td>\n",
       "      <td>-74.002640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>140</td>\n",
       "      <td>40.758492</td>\n",
       "      <td>-73.959206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173</td>\n",
       "      <td>374</td>\n",
       "      <td>40.760647</td>\n",
       "      <td>-73.984428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>127</td>\n",
       "      <td>481</td>\n",
       "      <td>40.731724</td>\n",
       "      <td>-74.006744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317</td>\n",
       "      <td>364</td>\n",
       "      <td>40.724537</td>\n",
       "      <td>-73.981857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>285</td>\n",
       "      <td>758</td>\n",
       "      <td>40.734547</td>\n",
       "      <td>-73.990738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   END_STATION_ID  F_COUNT_1D  F_AVG_LATITUDE_1D  F_AVG_LONGTITUDE_1D\n",
       "0             441         187          40.756016           -73.967415\n",
       "1             295         203          40.714066           -73.992943\n",
       "2             486         323          40.746201           -73.988556\n",
       "3             308         187          40.713078           -73.998512\n",
       "4             284         688          40.739017           -74.002640\n",
       "5            2022         140          40.758492           -73.959206\n",
       "6             173         374          40.760647           -73.984428\n",
       "7             127         481          40.731724           -74.006744\n",
       "8             317         364          40.724537           -73.981857\n",
       "9             285         758          40.734547           -73.990738"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.read.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset object materializes data in Parquet files on internal stages. Alternatively, you can use  `generate_training_set()` to output training data as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "|\"END_STATION_ID\"  |\"F_COUNT_1D\"  |\"F_AVG_LATITUDE_1D\"  |\"F_AVG_LONGTITUDE_1D\"  |\n",
      "---------------------------------------------------------------------------------\n",
      "|478               |268           |40.76030096          |-73.99884222           |\n",
      "|318               |550           |40.75320159          |-73.9779874            |\n",
      "|167               |326           |40.7489006           |-73.97604882           |\n",
      "|505               |483           |40.74901271          |-73.98848395           |\n",
      "|515               |394           |40.76009437          |-73.99461843           |\n",
      "|517               |431           |40.75149263          |-73.97798848           |\n",
      "|233               |183           |40.69246277          |-73.98963911           |\n",
      "|254               |297           |40.73532427          |-73.99800419           |\n",
      "|529               |388           |40.7575699           |-73.99098507           |\n",
      "|345               |451           |40.73649403          |-73.99704374           |\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_df = fs.generate_training_set(\n",
    "    spine_df=spine_df,\n",
    "    features=[training_fv]\n",
    ")\n",
    "\n",
    "training_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='delete-feature-views'></a>\n",
    "### Delete feature views\n",
    "\n",
    "Feature views can be deleted via `delete_feature_view()`.\n",
    "\n",
    "Warning: Deleting a feature view may break downstream dependencies for other feature views or models that depend on the feature view being deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "|\"NAME\"  |\"VERSION\"  |\n",
      "----------------------\n",
      "|        |           |\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in fs.list_feature_views().collect():\n",
    "    fv = fs.get_feature_view(row['NAME'], row['VERSION'])\n",
    "    fs.delete_feature_view(fv)\n",
    "\n",
    "all_fvs_df = fs.list_feature_views().select('name', 'version') \n",
    "assert all_fvs_df.count() == 0, \"0 feature views left after deletion.\"\n",
    "all_fvs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='delete-entities'></a>\n",
    "### Delete entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete entity with `delete_entity()`. Note it will check whether there are feature views registered on this entity before it gets deleted, otherwise the deletion will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|\"NAME\"  |\"JOIN_KEYS\"  |\"DESC\"  |\"OWNER\"  |\n",
      "-------------------------------------------\n",
      "|        |             |        |         |\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in fs.list_entities().collect():\n",
    "    fs.delete_entity(row['NAME'])\n",
    "\n",
    "all_entities_df = fs.list_entities()\n",
    "assert all_entities_df.count() == 0, \"0 entities after deletion.\"\n",
    "all_entities_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanup-feature-store'></a>\n",
    "### Cleanup Feature Store (experimental) \n",
    "\n",
    "Currently we provide an experimental API to delete all entities and feature views in a Feature Store for easy cleanup. If \"dryrun\" is set to True (the default) then `fs._clear()` only prints the objects that will be deleted. If \"dryrun\" is set to False, it performs the deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/snowml/snowflake/ml/feature_store/feature_store.py:190: UserWarning: It will clear ALL feature views and entities in this Feature Store. Make sure your role has sufficient access to all feature views and entities. Insufficient access to some feature views or entities will leave Feature Store in an incomplete state.\n",
      "  return f(self, *args, **kargs)\n"
     ]
    }
   ],
   "source": [
    "fs._clear(dryrun=False)\n",
    "\n",
    "assert fs.list_feature_views().count() == 0, \"0 feature views left after deletion.\"\n",
    "assert fs.list_entities().count() == 0, \"0 entities left after deletion.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanup-notebook'></a>\n",
    "## Clean up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully dropped.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(f\"DROP SCHEMA IF EXISTS {FS_DEMO_SCHEMA}\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
