{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69bc8786-3ea7-4b21-a53f-09675d86534b",
      "metadata": {
        "name": "cell1",
        "collapsed": false
      },
      "source": "# Introduction to Snowpark pandas\nThe Snowpark pandas API allows you to run your pandas code directly on your data in Snowflake. Built to replicate the functionality of pandas - including its data isolation and consistency guarantees - the Snowpark pandas API enables you to scale up your traditional pandas pipelines with just a few lines of change.\n\nIn today's demo, we'll show how you can get started with the Snowpark pandas API. We'll also see that the Snowpark pandas API is very similar to the native pandas API. \n\n## Importing Snowpark pandas\n\nSnowpark pandas is available in Snowpark Python version 1.17 and above. Snowpark Python comes pre-installed with the Snowflake Notebooks environment. Additionally, you will need to add the `modin` and `pandas` package in the `Packages` dropdown.\n\n- To install Modin, select `modin` from `Packages` and ensure the version is 0.28.1 or later.\n- To set the pandas version, select `pandas` from `Packages` and ensure the version is 2.2.1."
    },
    {
      "cell_type": "code",
      "id": "b806a16b-b666-4e38-b11c-5db618772a12",
      "metadata": {
        "language": "python",
        "name": "cell2",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "# Import the Snowpark pandas plugin for modin\nimport snowflake.snowpark.modin.plugin\nimport modin.pandas as pd",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9e7b7455-c1ad-4ad8-bf85-1ed2b0d516b8",
      "metadata": {
        "name": "cell3",
        "collapsed": false
      },
      "source": "## Create Snowpark session\nMuch like Snowpark, Snowpark pandas requires an active `Session` object to connect to your data in Snowflake. In the next cell, we'll be initializing a Session object, and importing Snowpark pandas as `pd`. Make sure to specify a database that you have write permissions on when creating the session, as Snowpark pandas requires write permissions."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ea2342c8-f661-4f86-8245-813f8b7ad0ab",
      "metadata": {
        "name": "cell4",
        "language": "python",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: Snowpark pandas has been in Public Preview since 1.17.0. See https://docs.snowflake.com/LIMITEDACCESS/snowpark-pandas for details.\n"
          ]
        }
      ],
      "source": "# Access current Snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()"
    },
    {
      "cell_type": "markdown",
      "id": "b3812257-0a82-43a0-aaac-d00681558890",
      "metadata": {
        "name": "cell5",
        "collapsed": false
      },
      "source": "## Reading Data from Snowflake\nToday, we'll be analyzing some Stock Timeseries Data from Snowflake's Marketplace. The data is available courtesy of Cybersyn Inc., and can be found [here](https://app.snowflake.com/marketplace/listing/GZTSZAS2KF7/cybersyn-inc-financial-economic-essentials). Let's start by reading the `stock_price_timeseries` table into a DataFrame!\n\nPlease double check that you have write permissions on the database that you initialized the Snowpark `Session` with. If using the `stock_price_timeseries` table from Snowflake's Marketplace, your `Session` needs to be configured to use a different database - one that you have write permissions over. The cell below uses the fully qualified name of the table to ensure that the read succeeds even though the `Session` is configured to use a different database!"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03298234-aabe-4548-99b1-bfdb609bdafb",
      "metadata": {
        "name": "cell6",
        "language": "python",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Took 7.316147916999999 seconds to read a table with 66904580 rows into Snowpark pandas!\n"
          ]
        }
      ],
      "source": [
        "# Read data into a Snowpark pandas df \n",
        "from time import perf_counter\n",
        "start = perf_counter()\n",
        "spd_df = pd.read_snowflake(\"FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\")\n",
        "end = perf_counter()\n",
        "data_size = len(spd_df)\n",
        "print(f\"Took {end - start} seconds to read a table with {data_size} rows into Snowpark pandas!\")\n",
        "snow_time = end - start"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f231df-fcc4-41e1-8809-314bae4b38ff",
      "metadata": {
        "name": "cell7",
        "collapsed": false
      },
      "source": "Now let's do the same by reading the data into vanilla pandas. (Note: This may take a while!)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b69ac2fd-c636-4bb5-a27d-58a5e4cbea7e",
      "metadata": {
        "scrolled": true,
        "name": "cell8",
        "language": "python",
        "codeCollapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Native pandas took 475.227207208 seconds to read the data!\n"
          ]
        }
      ],
      "source": [
        "# Read data into a local native pandas df - recommended to kill this cell after waiting a few minutes!\n",
        "\n",
        "from IPython import display\n",
        "start = perf_counter()\n",
        "\n",
        "# Create a cursor object.\n",
        "cur = session.connection.cursor()\n",
        "\n",
        "# Execute a statement that will generate a result set.\n",
        "sql = \"select * from FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\"\n",
        "cur.execute(sql)\n",
        "\n",
        "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
        "native_pd_df = cur.fetch_pandas_all()\n",
        "end = perf_counter()\n",
        "print(f\"Native pandas took {end - start} seconds to read the data!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72085630-11c4-4df1-9627-7c50c0957906",
      "metadata": {
        "name": "cell9",
        "collapsed": false
      },
      "source": [
        "It takes much longer for native pandas to read the table into memory than for Snowpark pandas to read the table."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c3dee5-62fe-46c6-a216-133a0140222d",
      "metadata": {
        "name": "cell10"
      },
      "source": [
        "## Examine The Raw Data\n",
        "Let's take a look at the data we're going to be working with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1a623bed-aed9-4cdb-a3c8-33e9e7da52af",
      "metadata": {
        "name": "cell11",
        "language": "python",
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TICKER</th>\n",
              "      <th>ASSET_CLASS</th>\n",
              "      <th>PRIMARY_EXCHANGE_CODE</th>\n",
              "      <th>PRIMARY_EXCHANGE_NAME</th>\n",
              "      <th>VARIABLE</th>\n",
              "      <th>VARIABLE_NAME</th>\n",
              "      <th>DATE</th>\n",
              "      <th>VALUE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GDV</td>\n",
              "      <td>Closed-End Funds</td>\n",
              "      <td>NYS</td>\n",
              "      <td>NEW YORK STOCK EXCHANGE</td>\n",
              "      <td>pre-market_open</td>\n",
              "      <td>Pre-Market Open</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>22.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EELV</td>\n",
              "      <td>ETF-Index Fund Shares</td>\n",
              "      <td>PSE</td>\n",
              "      <td>NYSE ARCA</td>\n",
              "      <td>pre-market_open</td>\n",
              "      <td>Pre-Market Open</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>23.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MCY</td>\n",
              "      <td>Equity</td>\n",
              "      <td>NYS</td>\n",
              "      <td>NEW YORK STOCK EXCHANGE</td>\n",
              "      <td>pre-market_open</td>\n",
              "      <td>Pre-Market Open</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>55.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISRL</td>\n",
              "      <td>Equity</td>\n",
              "      <td>NAS</td>\n",
              "      <td>NASDAQ CAPITAL MARKET</td>\n",
              "      <td>pre-market_open</td>\n",
              "      <td>Pre-Market Open</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACA</td>\n",
              "      <td>Equity</td>\n",
              "      <td>NYS</td>\n",
              "      <td>NEW YORK STOCK EXCHANGE</td>\n",
              "      <td>pre-market_open</td>\n",
              "      <td>Pre-Market Open</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>85.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  TICKER            ASSET_CLASS PRIMARY_EXCHANGE_CODE  \\\n",
              "0    GDV       Closed-End Funds                   NYS   \n",
              "1   EELV  ETF-Index Fund Shares                   PSE   \n",
              "2    MCY                 Equity                   NYS   \n",
              "3   ISRL                 Equity                   NAS   \n",
              "4    ACA                 Equity                   NYS   \n",
              "\n",
              "     PRIMARY_EXCHANGE_NAME         VARIABLE    VARIABLE_NAME        DATE  \\\n",
              "0  NEW YORK STOCK EXCHANGE  pre-market_open  Pre-Market Open  2024-06-04   \n",
              "1                NYSE ARCA  pre-market_open  Pre-Market Open  2024-06-04   \n",
              "2  NEW YORK STOCK EXCHANGE  pre-market_open  Pre-Market Open  2024-06-04   \n",
              "3    NASDAQ CAPITAL MARKET  pre-market_open  Pre-Market Open  2024-06-04   \n",
              "4  NEW YORK STOCK EXCHANGE  pre-market_open  Pre-Market Open  2024-06-04   \n",
              "\n",
              "   VALUE  \n",
              "0  22.45  \n",
              "1  23.65  \n",
              "2  55.51  \n",
              "3  10.98  \n",
              "4  85.40  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "import streamlit as st\nst.dataframe(spd_df.head(5))"
    },
    {
      "cell_type": "markdown",
      "id": "2822e6ae-9810-4ca1-8646-660eb3e68d97",
      "metadata": {
        "name": "cell12",
        "collapsed": false
      },
      "source": [
        "## Filtering The Data\n",
        "Let's take a look at some common data transformations - starting with filtering! Let's filter for stocks that are listed on the New York Stock Exchange!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4218fceb-68f1-41be-8c08-3f6ad51424d5",
      "metadata": {
        "name": "cell13",
        "language": "python",
        "codeCollapsed": false,
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering for stocks belonging to the NYSE took 1.3051991250000015 seconds in Snowpark pandas\n"
          ]
        }
      ],
      "source": "start = perf_counter()\nnyse_spd_df = spd_df[(spd_df['PRIMARY_EXCHANGE_CODE'] == 'NYS')]\nrepr(nyse_spd_df)\nend = perf_counter()\nst.dataframe(nyse_spd_df.head())\nprint(f\"Filtering for stocks belonging to the NYSE took {end - start} seconds in Snowpark pandas\")"
    },
    {
      "cell_type": "markdown",
      "id": "c2e325b5-8e24-4dbc-93da-c2e93d84590f",
      "metadata": {
        "name": "cell14",
        "collapsed": false
      },
      "source": [
        "Let's try an even more granular filter - let's filter for the Pre-Market Open of stocks that have the following tickers:\n",
        "* GOOG (Alphabet, Inc.)\n",
        "* MSFT (Microsoft)\n",
        "* SNOW (Snowflake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5d456c29-7689-4599-bcd6-02c646ef8f58",
      "metadata": {
        "name": "cell15",
        "language": "python",
        "codeCollapsed": false,
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering for the Pre-Market Open price for the above stocks took 1.4652052499999968 seconds in Snowpark pandas\n"
          ]
        }
      ],
      "source": "start = perf_counter()\nfiltered_spd_df = spd_df[((spd_df['TICKER'] == 'GOOG') | (spd_df['TICKER'] == 'MSFT') | (spd_df['TICKER'] == 'SNOW')) & (spd_df['VARIABLE_NAME'] == 'Pre-Market Open')]\nrepr(filtered_spd_df)\nend = perf_counter()\nst.dataframe(filtered_spd_df.head())\nprint(f\"Filtering for the Pre-Market Open price for the above stocks took {end - start} seconds in Snowpark pandas\")"
    },
    {
      "cell_type": "markdown",
      "id": "a8d5cb07-ccce-481e-b41e-770d4de91b0f",
      "metadata": {
        "name": "cell16",
        "collapsed": false
      },
      "source": [
        "# Reshaping the Data\n",
        "Let's say we wanted to analyse the performance of various stock prices across time - in that case, it may be more helpful to have the values as columns, and the ticker name and date as the index - rather than the current encoding. We can accomplish this using the `pivot_table` API!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2f8f893a-c7dc-4e08-bace-3c93ada282cf",
      "metadata": {
        "name": "cell17",
        "language": "python",
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pivoting the DataFrame took 4.764952458999971 seconds in Snowpark pandas\n"
          ]
        }
      ],
      "source": "start = perf_counter()\nreshape_df = spd_df.pivot_table(index=[\"TICKER\", \"DATE\"], columns=\"VARIABLE_NAME\", values=\"VALUE\")\nrepr(reshape_df)\nend = perf_counter()\nprint(f\"Pivoting the DataFrame took {end - start} seconds in Snowpark pandas\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "65c0b9d1-a3be-4d05-9481-f54628f3b793",
      "metadata": {
        "name": "cell18",
        "language": "python",
        "codeCollapsed": false,
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VARIABLE_NAME</th>\n",
              "      <th>All-Day High</th>\n",
              "      <th>All-Day Low</th>\n",
              "      <th>Nasdaq Volume</th>\n",
              "      <th>Post-Market Close</th>\n",
              "      <th>Pre-Market Open</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TICKER</th>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
              "      <th>2018-05-01</th>\n",
              "      <td>66.35</td>\n",
              "      <td>65.50</td>\n",
              "      <td>439231.0</td>\n",
              "      <td>66.23</td>\n",
              "      <td>65.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-02</th>\n",
              "      <td>66.86</td>\n",
              "      <td>65.81</td>\n",
              "      <td>316586.0</td>\n",
              "      <td>65.91</td>\n",
              "      <td>66.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-03</th>\n",
              "      <td>66.46</td>\n",
              "      <td>64.85</td>\n",
              "      <td>407491.0</td>\n",
              "      <td>66.33</td>\n",
              "      <td>65.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-04</th>\n",
              "      <td>67.25</td>\n",
              "      <td>65.63</td>\n",
              "      <td>269025.0</td>\n",
              "      <td>66.99</td>\n",
              "      <td>66.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-07</th>\n",
              "      <td>67.98</td>\n",
              "      <td>67.08</td>\n",
              "      <td>263454.0</td>\n",
              "      <td>67.40</td>\n",
              "      <td>67.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "VARIABLE_NAME      All-Day High  All-Day Low  Nasdaq Volume  \\\n",
              "TICKER DATE                                                   \n",
              "A      2018-05-01         66.35        65.50       439231.0   \n",
              "       2018-05-02         66.86        65.81       316586.0   \n",
              "       2018-05-03         66.46        64.85       407491.0   \n",
              "       2018-05-04         67.25        65.63       269025.0   \n",
              "       2018-05-07         67.98        67.08       263454.0   \n",
              "\n",
              "VARIABLE_NAME      Post-Market Close  Pre-Market Open  \n",
              "TICKER DATE                                            \n",
              "A      2018-05-01              66.23            65.64  \n",
              "       2018-05-02              65.91            66.01  \n",
              "       2018-05-03              66.33            65.91  \n",
              "       2018-05-04              66.99            66.06  \n",
              "       2018-05-07              67.40            67.16  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "st.dataframe(reshape_df.head())"
    },
    {
      "cell_type": "markdown",
      "id": "3121c325-d7cf-47d6-a2d7-e759ece59d11",
      "metadata": {
        "name": "cell19",
        "collapsed": false
      },
      "source": [
        "## Transforming the Data\n",
        "Now that we have reformatted the data, we can beginn to apply some transformations. Let's start by taking a look at the All-Day Low column for the tickers above - we can resample the data to look at the Quarterly Low for the `GOOG` ticker!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b06f23b-12dc-4387-bb87-bc4cbcff6a85",
      "metadata": {
        "name": "cell20",
        "language": "python",
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampling the DataFrame took 2.1228156670000544 seconds in Snowpark pandas\n"
          ]
        }
      ],
      "source": [
        "start = perf_counter()\n",
        "resampled_spd_df_all_quarter_low = reshape_df[\"All-Day Low\"][\"GOOG\"].resample(\"91D\").min()\n",
        "repr(resampled_spd_df_all_quarter_low)\n",
        "end = perf_counter()\n",
        "print(f\"Resampling the DataFrame took {end - start} seconds in Snowpark pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8978f55a-c28a-4b7f-9f20-4a2952d2a857",
      "metadata": {
        "name": "cell21",
        "language": "python",
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DATE\n",
              "2018-05-01    1006.48\n",
              "2018-07-31     995.58\n",
              "2018-10-30     968.09\n",
              "2019-01-29    1055.85\n",
              "2019-04-30    1025.06\n",
              "2019-07-30    1125.00\n",
              "2019-10-29    1250.79\n",
              "2020-01-28    1013.54\n",
              "2020-04-28    1218.04\n",
              "2020-07-28    1399.96\n",
              "2020-10-27    1514.61\n",
              "2021-01-26    1801.22\n",
              "2021-04-27    2223.89\n",
              "2021-07-27    2623.00\n",
              "2021-10-26    2493.01\n",
              "2022-01-25    2363.60\n",
              "2022-04-26     107.01\n",
              "2022-07-26      94.93\n",
              "2022-10-25      83.00\n",
              "2023-01-24      88.87\n",
              "2023-04-25     101.66\n",
              "2023-07-25     121.54\n",
              "2023-10-24     121.47\n",
              "2024-01-23     131.54\n",
              "2024-04-23     152.77\n",
              "Freq: None, Name: All-Day Low, dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "print(resampled_spd_df_all_quarter_low)"
    },
    {
      "cell_type": "markdown",
      "id": "c512e74d-7316-44de-a644-917270d38fac",
      "metadata": {
        "name": "cell22",
        "collapsed": false
      },
      "source": [
        "We can even take a look at the quarter-over-quarter fluctuation in prices using the `diff` API!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fb467dd6-cc74-423f-b17b-46541f5bbff8",
      "metadata": {
        "name": "cell23",
        "language": "python",
        "codeCollapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diffing the resampled data took 1.2249565410000969 seconds in Snowpark pandas\n"
          ]
        }
      ],
      "source": [
        "start = perf_counter()\n",
        "q_o_q_resampled_spd_df_all_quarter_low = resampled_spd_df_all_quarter_low.diff()\n",
        "repr(q_o_q_resampled_spd_df_all_quarter_low)\n",
        "end = perf_counter()\n",
        "print(f\"Diffing the resampled data took {end - start} seconds in Snowpark pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "866628d5-5bf9-4212-bba2-bf5e816a70e1",
      "metadata": {
        "name": "cell24",
        "language": "python"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DATE\n",
              "2018-05-01        NaN\n",
              "2018-07-31     -10.90\n",
              "2018-10-30     -27.49\n",
              "2019-01-29      87.76\n",
              "2019-04-30     -30.79\n",
              "2019-07-30      99.94\n",
              "2019-10-29     125.79\n",
              "2020-01-28    -237.25\n",
              "2020-04-28     204.50\n",
              "2020-07-28     181.92\n",
              "2020-10-27     114.65\n",
              "2021-01-26     286.61\n",
              "2021-04-27     422.67\n",
              "2021-07-27     399.11\n",
              "2021-10-26    -129.99\n",
              "2022-01-25    -129.41\n",
              "2022-04-26   -2256.59\n",
              "2022-07-26     -12.08\n",
              "2022-10-25     -11.93\n",
              "2023-01-24       5.87\n",
              "2023-04-25      12.79\n",
              "2023-07-25      19.88\n",
              "2023-10-24      -0.07\n",
              "2024-01-23      10.07\n",
              "2024-04-23      21.23\n",
              "Freq: None, Name: All-Day Low, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "print(q_o_q_resampled_spd_df_all_quarter_low)"
    },
    {
      "cell_type": "markdown",
      "id": "a7593697-feb5-40a7-9d6c-7c011ad35186",
      "metadata": {
        "name": "cell25",
        "collapsed": false
      },
      "source": "## Apply function along an axis\nNow we want to apply the absolute value square root on each value in the series. \nSnowpark pandas supports `apply` which applies some arbitrary user-defined Python function along a particular axis of the DataFrame or Series. "
    },
    {
      "cell_type": "markdown",
      "id": "15d4f702-c94f-4006-90e5-d7f6b988076c",
      "metadata": {
        "name": "cell26",
        "collapsed": false
      },
      "source": "The Python function is serialized into Python bytecode and run this as a UDF inside Snowpark\u2019s Python secure sandbox runtime environment. Snowpark's Python runtime environment is seamlessly integrated with the Anaconda package manager so that users can leverage their favorite third-party packages such as NumPy for flexible data transformation within their dataframe apply. \n\n**Pro Tip:** While calling `apply` is convenient, since the underlying implementation are UDF or UDTFs, it may not be as optimized as SQL queries transpiled from other Snowpark pandas queries. If the function applied has an equivalent dataframe or series operation, we recommend using those operations instead. For example, instead of `df.groupby('col1').apply('sum')`, directly call `df.groupby('col1').sum()`."
    },
    {
      "cell_type": "code",
      "id": "0c3775af-8fe8-48f3-abd4-f783c0d27528",
      "metadata": {
        "language": "python",
        "name": "cell27",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "import numpy as np\nresampled_all_quarter_low_df_sqrt = q_o_q_resampled_spd_df_all_quarter_low.apply(\n    lambda x: np.sqrt(abs(x))\n)",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e45dbe2f-8bd3-46db-8c31-f39994db6b99",
      "metadata": {
        "language": "python",
        "name": "cell28",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "resampled_all_quarter_low_df_sqrt = resampled_all_quarter_low_df_sqrt.dropna()\nprint(resampled_all_quarter_low_df_sqrt)",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1c9bb36e-ec88-4ad6-8004-2968c548214d",
      "metadata": {
        "name": "cell29",
        "collapsed": false
      },
      "source": "### Conclusion\nSnowpark pandas is able to replicate the pandas API while performing computations on large data sets that don't typically work with native pandas and all while keeping your data in Snowflake! To learn more about Snowpark pandas, see [Snowflake Documentation](https://docs.snowflake.com/developer-guide/snowpark/python/snowpark-pandas)."
    }
  ]
}